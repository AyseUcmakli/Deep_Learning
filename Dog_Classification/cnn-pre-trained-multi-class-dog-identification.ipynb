{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7327,"databundleVersionId":861871,"sourceType":"competition"}],"dockerImageVersionId":30589,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"background-color:#FF6961; font-family:newtimeroman;color:#FFF9ED;font-size:220%; text-align:center; border-radius: 15px 55px;\">üêæ üêï DogVision: Multi-Class Dog Breed Identification with CNNs and Pre-trained Models üê© </p>\n","metadata":{"id":"gEdvdaatMSmK"}},{"cell_type":"markdown","source":"![image.png](https://storage.googleapis.com/kaggle-media/competitions/kaggle/3333/media/border_collies.png)\n[Dog Breed Identification - Kaggle](https://www.kaggle.com/c/dog-breed-identification)","metadata":{}},{"cell_type":"markdown","source":"# WELCOME!","metadata":{"cell_style":"split","heading_collapsed":true,"id":"CvFxPmf41b6y"}},{"cell_type":"markdown","source":"<h3 style=\"text-align:center;font-size:200%;\">Progress Bars</h3>\n<div class=\"progress\">\n  <div class=\"progress-bar bg-danger\" role=\"progressbar\" style=\"width: 0%;\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">0%</div>\n</div>\n\n","metadata":{"id":"eF9tS6Y7RvDK"}},{"cell_type":"markdown","source":"<ul class=\"nav flex-column\" style=\"padding: 0;\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\" style=\"background-color:#FF6961; color:white; text-align: center; margin-bottom: 20px;\"><b>Contributors</b></h3>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n      <span style=\"color:#FF6961; flex-grow: 1;\">Zeynep Parmak</span>\n      <a href=\"https://www.linkedin.com/in/zeynepparmak\" target=\"_blank\">\n        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n      <a href=\"https://www.kaggle.com/zeynepparmak\" target=\"_blank\">\n        <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n    </div>\n  </li>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n      <span style=\"color:#FF6961; flex-grow: 1;\">Ay≈üe U√ßmaklƒ±</span>\n      <a href=\"https://www.linkedin.com/in/ayse-ucmakli\" target=\"_blank\">\n        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n      <a href=\"https://www.kaggle.com/ayeucmakli\" target=\"_blank\">\n        <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n    </div>\n  </li>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n      <span style=\"color:#FF6961; flex-grow: 1;\">Elif Aker</span>\n      <a href=\"https://www.linkedin.com/in/elif-aker\" target=\"_blank\">\n        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n      <a href=\"https://www.kaggle.com/vaktievvel\" target=\"_blank\">\n        <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n    </div>\n  </li>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n        <span style=\"color:#FF6961; flex-grow: 1;\">Safiye Olgun</span>\n        <a href=\"https://www.linkedin.com/in/safiyeolgun/\" target=\"_blank\">\n            <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n        </a>\n        <a href=\"https://www.kaggle.com/safiyeolgun\" target=\"_blank\">\n            <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n        </a>\n    </div>\n</li>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n      <span style=\"color:#FF6961; flex-grow: 1;\">H√ºseyin Cenik</span>\n      <a href=\"https://www.linkedin.com/in/huseyincenik/\" target=\"_blank\">\n        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n      <a href=\"https://www.kaggle.com/huseyincenik\" target=\"_blank\">\n        <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n    </div>\n  </li>\n</ul>\n","metadata":{"id":"M-0g5b4bTppZ"}},{"cell_type":"markdown","source":"<a id=\"toc\"></a>\n<div style=\"border-radius: 10px;\n            border: black solid;\n            background-color: lightblue;\n            font-size: 100%;\n            text-align: left;\n            box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n<h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: white; background-color: red;\"><center> ‚úç‚úç Content ‚úç‚úç</center></h2>  \n<div style=\"display: flex;\">\n    <hr style=\"border: none;\n               height: 2px;\n               width: 100%;\n               background-color: linear-gradient(to right, blue, white);\n               box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.5);\n               margin-left: 0;\">\n</div>      \n<div>\n  <ul style=\"background-color: white;\">\n    <li><a href=\"#part_1\">PART - 1 ( CNN )</a></li>\n    <li><a href=\"#part_2\">PART - 2 ( FEATURE EXTRACTOR - TRANSFER LEARNING )</a></li>\n    </ul>\n</div>\n<div style=\"display: flex;\">\n    <hr style=\"border: none;\n               height: 2px;\n               width: 100%;\n               background-color: linear-gradient(to right, blue, white);\n               box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.5);\n               margin-left: 0;\">\n</div>\n<div>\n  <ul style=\"background-color: white;\">\n    <li><a href=\"#part_2_model_comparison\">MODEL COMPARISON</a></li>\n    <li><a href=\"#part_2_prediction\">PREDICTION</a></li>\n    <li><a href=\"#summary\">SUMMARY</a></li>\n    <li><a href=\"#the_end\">THE END </a></li>\n  </ul>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"part_1\"></a>\n# <p style=\"background-color:#FF6961; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® PART - 1 ( CNN  ) ‚ú®</p>\n\n","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"_teyk4ESTyGE"}},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">\n    Content\n  </h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#part_1_dataset\" role=\"tab\" aria-controls=\"profile\">\n    Dataset Explanation\n    <span class=\"badge badge-primary badge-pill\">1</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#part_1_importing\" role=\"tab\" aria-controls=\"messages\">\n    Importing Libraries Needed in This Notebook\n    <span class=\"badge badge-primary badge-pill\">2</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_1_data_aug\" role=\"tab\" aria-controls=\"settings\">\n    Data Augmentation\n    <span class=\"badge badge-primary badge-pill\">3</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_1_model_train\" role=\"tab\" aria-controls=\"settings\">\n    Train - Test Split\n    <span class=\"badge badge-primary badge-pill\">4</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_1_model_class\" role=\"tab\" aria-controls=\"settings\">\n    Class Weight\n    <span class=\"badge badge-primary badge-pill\">5</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_1_model_fit\" role=\"tab\" aria-controls=\"settings\">\n    Training Model\n    <span class=\"badge badge-primary badge-pill\">6</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_1_model_evaluation\" role=\"tab\" aria-controls=\"settings\">\n    Model Evaluation\n    <span class=\"badge badge-primary badge-pill\">7</span>\n  </a>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"part_1_dataset\"></a>\n<div style=\"border-radius: 10px; border: 1px solid black; background-color:#3498DB ; font-size: 100%; text-align: left; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); padding: 10px; margin-bottom: 20px;\">\n    <h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: #FF5733; background-color: white; padding: 10px; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">‚ö°Ô∏è Dataset Explanation ‚ö°Ô∏è</h2>\n    <p>\n        <strong style=\"color: white;\">About the Dataset:</strong>\n        The dataset provided for this competition is a subset of ImageNet focusing strictly on canine images. It aims to facilitate practice in fine-grained image categorization, particularly in identifying various breeds of dogs.\n    </p>\n    <p>\n        <strong style=\"color: white;\">Acknowledgments:</strong>\n        The creators of the Stanford Dogs Dataset‚ÄîAditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Fei-Fei Li‚Äîare acknowledged for enabling this competition.\n    </p>\n    <p>\n        <strong style=\"color: white;\">Evaluation:</strong>\n        Submissions are assessed based on Multi Class Log Loss, measuring the similarity between predicted probabilities and observed targets.\n    </p>\n    <p>\n        <strong style=\"color: white;\">Submission Format:</strong>\n        Participants are required to predict probabilities for each of the different dog breeds for the images in the test set. Submissions should adhere to a specific format, including IDs and predicted probabilities.\n    </p>\n    <p>\n        <strong style=\"color: white;\">Citation:</strong>\n        Will Cukierski. (2017). Dog Breed Identification. Kaggle. [Competition Link](https://kaggle.com/competitions/dog-breed-identification)\n    </p>\n</div>\n","metadata":{"id":"L3ESxHSGT4eS"}},{"cell_type":"markdown","source":"<a id=\"part_1_importing\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Importing Libraries Needed in This Notebook ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, cv2, random, time, shutil, csv\n\n\nplt.rcParams[\"figure.figsize\"] = (10, 6)\n\nsns.set_style(\"whitegrid\")\npd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n\n\n\n# !pip install termcolor\nimport colorama\nfrom colorama import Fore, Style  # makes strings colored\nfrom termcolor import colored\nfrom termcolor import cprint\n\nfrom tensorflow import keras\nimport tensorflow as tf\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras import regularizers\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tqdm import tqdm\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.layers import (\n    Activation,\n    Dropout,\n    Flatten,\n    Dense,\n    Conv2D,\n    MaxPooling2D,\n    BatchNormalization\n)\n\n\nfrom sklearn.model_selection import cross_val_score, cross_validate \nfrom sklearn.metrics import RocCurveDisplay,accuracy_score, f1_score, recall_score,\\\n                            precision_score, make_scorer,\\\n                            classification_report,confusion_matrix,\\\n                            ConfusionMatrixDisplay, average_precision_score,\\\n                            roc_curve, roc_auc_score, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom scikitplot.metrics import plot_roc, precision_recall_curve,average_precision_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import label_binarize\n\n\n\n\n# Uncomment the following lines if you want to suppress warnings:\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.warn(\"this will not show\")\n\n# Set it to None to display all rows in the dataframe:\n# pd.set_option('display.max_rows', None)\n\n# Set it to None to display all columns in the dataframe:\npd.set_option(\"display.max_columns\", None)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:53:57.569619Z","iopub.execute_input":"2023-12-14T06:53:57.570573Z","iopub.status.idle":"2023-12-14T06:53:58.550789Z","shell.execute_reply.started":"2023-12-14T06:53:57.570534Z","shell.execute_reply":"2023-12-14T06:53:58.549775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"labels_csv = pd.read_csv(\"../input/dog-breed-identification/labels.csv\")\nprint(labels_csv.describe())\nprint(labels_csv.head())","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:53:58.552955Z","iopub.execute_input":"2023-12-14T06:53:58.553680Z","iopub.status.idle":"2023-12-14T06:53:58.613489Z","shell.execute_reply.started":"2023-12-14T06:53:58.553641Z","shell.execute_reply":"2023-12-14T06:53:58.612250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How many images are there of each breed?\nlabels_csv[\"breed\"].value_counts().plot.bar(figsize=(20, 10));","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:53:58.614915Z","iopub.execute_input":"2023-12-14T06:53:58.615322Z","iopub.status.idle":"2023-12-14T06:54:01.307455Z","shell.execute_reply.started":"2023-12-14T06:53:58.615283Z","shell.execute_reply":"2023-12-14T06:54:01.306503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#info\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Info</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"15bbec17"}},{"cell_type":"markdown","source":"<div style=\"background-color:#3498DB; padding:10px; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p style=\"font-weight: bold; color: white;\">Working with an imbalanced dataset where the minimum number of instances in any class is observed to be 60.</p>\n</div>\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, Image\nImage(\"/kaggle/input/dog-breed-identification/train/00693b8bc2470375cc744a6391d397ec.jpg\")","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:01.310292Z","iopub.execute_input":"2023-12-14T06:54:01.310655Z","iopub.status.idle":"2023-12-14T06:54:01.322804Z","shell.execute_reply.started":"2023-12-14T06:54:01.310626Z","shell.execute_reply":"2023-12-14T06:54:01.321703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"# Define our training file path for ease of use\ntrain_path = \"../input/dog-breed-identification/train/\"","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:01.323917Z","iopub.execute_input":"2023-12-14T06:54:01.324792Z","iopub.status.idle":"2023-12-14T06:54:01.330248Z","shell.execute_reply.started":"2023-12-14T06:54:01.324748Z","shell.execute_reply":"2023-12-14T06:54:01.329093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create pathnames from image ID's\nfilenames = [train_path + fname + \".jpg\" for fname in labels_csv[\"id\"]]\n\n# Check the first 10 filenames\nfilenames[:10]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:01.331703Z","iopub.execute_input":"2023-12-14T06:54:01.332054Z","iopub.status.idle":"2023-12-14T06:54:01.348947Z","shell.execute_reply.started":"2023-12-14T06:54:01.332025Z","shell.execute_reply":"2023-12-14T06:54:01.347901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check whether number of filenames matches number of actual image files\nimport os\nif len(os.listdir(train_path)) == len(filenames):\n  print(\"Filenames match actual amount of files!\")\nelse:\n  print(\"Filenames do not match actual amount of files, check the target directory.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:01.350246Z","iopub.execute_input":"2023-12-14T06:54:01.350583Z","iopub.status.idle":"2023-12-14T06:54:01.658175Z","shell.execute_reply.started":"2023-12-14T06:54:01.350554Z","shell.execute_reply":"2023-12-14T06:54:01.657266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"from PIL import Image\nimport random\n\n\nrandom_images = random.sample(filenames, 9)\n\nfig, axes = plt.subplots(3, 3, figsize=(10, 10))\n\nfor i, ax in enumerate(axes.flat):\n    \n    img_path = random_images[i]\n    img = Image.open(img_path)\n    label = labels_csv[labels_csv[\"id\"] == os.path.splitext(os.path.basename(img_path))[0]][\"breed\"].values[0]\n    \n    img = img.resize((100, 100))\n    ax.imshow(img)\n    ax.set_title(label)\n    ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:01.659626Z","iopub.execute_input":"2023-12-14T06:54:01.660553Z","iopub.status.idle":"2023-12-14T06:54:04.544996Z","shell.execute_reply.started":"2023-12-14T06:54:01.660509Z","shell.execute_reply":"2023-12-14T06:54:04.543859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"import numpy as np\nlabels = labels_csv[\"breed\"].to_numpy() # convert labels column to NumPy array\nlabels[:20]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:04.546218Z","iopub.execute_input":"2023-12-14T06:54:04.546560Z","iopub.status.idle":"2023-12-14T06:54:04.553494Z","shell.execute_reply.started":"2023-12-14T06:54:04.546532Z","shell.execute_reply":"2023-12-14T06:54:04.552487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See if number of labels matches the number of filenames\nif len(labels) == len(filenames):\n  print(\"Number of labels matches number of filenames!\")\nelse:\n  print(\"Number of labels does not match number of filenames, check data directories.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:04.558678Z","iopub.execute_input":"2023-12-14T06:54:04.559381Z","iopub.status.idle":"2023-12-14T06:54:04.564410Z","shell.execute_reply.started":"2023-12-14T06:54:04.559348Z","shell.execute_reply":"2023-12-14T06:54:04.563507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"# Find the unique label values\nunique_breeds = np.unique(labels)\nlen(unique_breeds)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:04.565658Z","iopub.execute_input":"2023-12-14T06:54:04.565952Z","iopub.status.idle":"2023-12-14T06:54:04.586470Z","shell.execute_reply.started":"2023-12-14T06:54:04.565927Z","shell.execute_reply":"2023-12-14T06:54:04.585468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn every label into a boolean array\nboolean_labels = [label == np.array(unique_breeds) for label in labels]\nboolean_labels[:2]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:04.588251Z","iopub.execute_input":"2023-12-14T06:54:04.588697Z","iopub.status.idle":"2023-12-14T06:54:04.710124Z","shell.execute_reply.started":"2023-12-14T06:54:04.588662Z","shell.execute_reply":"2023-12-14T06:54:04.709233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example: Turning a boolean array into integers\nprint(labels[1]) # original label\nprint(np.where(unique_breeds == labels[1])[0][0]) # index where label occurs\nprint(boolean_labels[1].argmax()) # index where label occurs in boolean array\nprint(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:04.711250Z","iopub.execute_input":"2023-12-14T06:54:04.711538Z","iopub.status.idle":"2023-12-14T06:54:04.718894Z","shell.execute_reply.started":"2023-12-14T06:54:04.711514Z","shell.execute_reply":"2023-12-14T06:54:04.717780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"# Setup X & y variables\nX = filenames\ny = boolean_labels\n\nprint(f\"Number of training images: {len(X)}\")\nprint(f\"Number of labels: {len(y)}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:04.720394Z","iopub.execute_input":"2023-12-14T06:54:04.721281Z","iopub.status.idle":"2023-12-14T06:54:04.727790Z","shell.execute_reply.started":"2023-12-14T06:54:04.721240Z","shell.execute_reply":"2023-12-14T06:54:04.726840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Setup X & y variables\nX = filenames\ny = [np.where(label)[0][0] for label in boolean_labels]\n\n# Create a DataFrame\ntrain_df = pd.DataFrame({'image': X, 'label': y})\n\n# Display the DataFrame\ntrain_df.sample(10)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:04.728925Z","iopub.execute_input":"2023-12-14T06:54:04.729238Z","iopub.status.idle":"2023-12-14T06:54:04.820075Z","shell.execute_reply.started":"2023-12-14T06:54:04.729200Z","shell.execute_reply":"2023-12-14T06:54:04.819035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(train_df.iloc[1])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:04.821251Z","iopub.execute_input":"2023-12-14T06:54:04.821573Z","iopub.status.idle":"2023-12-14T06:54:04.828558Z","shell.execute_reply.started":"2023-12-14T06:54:04.821547Z","shell.execute_reply":"2023-12-14T06:54:04.827563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"refactor_size = 64\nresized_image_list = []\nall_paths = []\n\n# Loop through the DataFrame to load and process images\nfor i in range(len(train_df)):\n    image_path = train_df.iloc[i]['image']\n    label = train_df.iloc[i]['label']\n\n    # Load and process the image\n    img = tf.keras.utils.load_img(image_path, target_size=(refactor_size, refactor_size))\n    img_vals = tf.image.convert_image_dtype(img, tf.float32)\n    imgarr = tf.keras.utils.img_to_array(img_vals)\n\n    # Append the processed image and label to the lists\n    resized_image_list.append(imgarr)\n    all_paths.append(image_path)\n\n# Convert the lists to numpy arrays\nresized_image_list = np.asarray(resized_image_list)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:54:04.829874Z","iopub.execute_input":"2023-12-14T06:54:04.830247Z","iopub.status.idle":"2023-12-14T06:55:20.643929Z","shell.execute_reply.started":"2023-12-14T06:54:04.830212Z","shell.execute_reply":"2023-12-14T06:55:20.642925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nprint(\"Available GPUs:\", gpus)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:20.645364Z","iopub.execute_input":"2023-12-14T06:55:20.645733Z","iopub.status.idle":"2023-12-14T06:55:20.651496Z","shell.execute_reply.started":"2023-12-14T06:55:20.645706Z","shell.execute_reply":"2023-12-14T06:55:20.650413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nrow = 5\nncol = 4  \nfig1 = plt.figure(figsize=(20, 15))\nfig1.suptitle('After Resizing', size=32)\n\nfor i in range(min(20, len(resized_image_list))):\n    plt.subplot(nrow, ncol, i + 1)\n    plt.imshow(resized_image_list[i])\n    plt.title('class = {x}, Dog is {y}'.format(x=train_df[\"label\"].iloc[i], y=labels[i]))\n    plt.axis('Off')\n    plt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:20.652973Z","iopub.execute_input":"2023-12-14T06:55:20.653365Z","iopub.status.idle":"2023-12-14T06:55:24.164517Z","shell.execute_reply.started":"2023-12-14T06:55:20.653332Z","shell.execute_reply":"2023-12-14T06:55:24.163495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_1_data_aug\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Data Augmentation ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"markdown","source":"![image.png](https://www.baeldung.com/wp-content/uploads/sites/4/2022/08/AugmentData.png)\n[Credit](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.baeldung.com%2Fcs%2Fml-data-augmentation&psig=AOvVaw09snYZgTuBqA-qUMBKYYYj&ust=1701605614028000&source=images&cd=vfe&opi=89978449&ved=0CBEQjRxqFwoTCJDYxYPd8IIDFQAAAAAdAAAAABBG)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ndata_augmentation = keras.Sequential([\n    layers.RandomFlip(\"horizontal\"), \n    layers.RandomRotation(0.3),\n    layers.RandomZoom(0.2),\n    layers.RandomContrast(0.5)\n], name='data_augmentation')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:24.166019Z","iopub.execute_input":"2023-12-14T06:55:24.166453Z","iopub.status.idle":"2023-12-14T06:55:24.185945Z","shell.execute_reply.started":"2023-12-14T06:55:24.166396Z","shell.execute_reply":"2023-12-14T06:55:24.184990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_images = data_augmentation(resized_image_list)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:24.187569Z","iopub.execute_input":"2023-12-14T06:55:24.188282Z","iopub.status.idle":"2023-12-14T06:55:25.346428Z","shell.execute_reply.started":"2023-12-14T06:55:24.188239Z","shell.execute_reply":"2023-12-14T06:55:25.345421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nrow = 4\nncol = 5\n\naugmented_indices = range(min(20, len(resized_image_list)))\n\nfig2 = plt.figure(figsize=(20, 15))\nfig2.suptitle('After Augmentation', size=32)\n\nfor i, idx in enumerate(augmented_indices):\n    augmented_image = data_augmentation(tf.expand_dims(resized_image_list[idx], 0), training=True)\n    plt.subplot(nrow, ncol, i + 1)\n    plt.imshow(augmented_image[0].numpy())\n    plt.title('class = {x}, Dog is {y}'.format(x=train_df[\"label\"].iloc[idx], y=labels[idx]))\n    plt.axis('Off')\n    plt.grid(False)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:25.348203Z","iopub.execute_input":"2023-12-14T06:55:25.348539Z","iopub.status.idle":"2023-12-14T06:55:30.041826Z","shell.execute_reply.started":"2023-12-14T06:55:25.348509Z","shell.execute_reply":"2023-12-14T06:55:30.040721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_values = train_df[\"label\"]\nfiltered_values = class_values[class_values < 0]\n\nif not filtered_values.empty:\n    print(\"There are values in the series less than 0.\")\nelse:\n    print(\"There are no values in the series less than 0.\")\nclass_values.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:30.043343Z","iopub.execute_input":"2023-12-14T06:55:30.043761Z","iopub.status.idle":"2023-12-14T06:55:30.058941Z","shell.execute_reply.started":"2023-12-14T06:55:30.043723Z","shell.execute_reply":"2023-12-14T06:55:30.057743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_1_model_train\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Train - Test Split ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"# Assuming you have NumPy arrays for augmented_images and selected_labels\n# Convert NumPy arrays to TensorFlow tensors\naugmented_images_tf = tf.convert_to_tensor(augmented_images)\nselected_labels_tf = tf.convert_to_tensor(train_df['label'])\n\n# Convert TensorFlow tensors back to NumPy arrays\naugmented_images_np = augmented_images_tf.numpy()\nselected_labels_np = selected_labels_tf.numpy()\n\n# Split them into training and validation using NUM_IMAGES \nX_train, X_test, y_train, y_test = train_test_split(\n    augmented_images_np, \n    selected_labels_np,\n    test_size=0.1,\n    stratify = selected_labels_np,\n    random_state=42\n)\n\n# X_train, X_val, y_train, y_val = train_test_split(\n#     X_train, \n#     y_train,\n#     test_size=0.1,  # You can adjust the validation split as needed\n#     stratify = y_train,\n#     random_state=42\n# )\n\nprint(\"Training Set Length:\", len(X_train))\nprint(\"Test Set Length:\", len(X_test))                                  \n# print(\"Validation Set Length:\", len(X_val))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:30.060247Z","iopub.execute_input":"2023-12-14T06:55:30.060622Z","iopub.status.idle":"2023-12-14T06:55:30.842911Z","shell.execute_reply.started":"2023-12-14T06:55:30.060583Z","shell.execute_reply":"2023-12-14T06:55:30.841871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_1_model_class\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Class Weight ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\n\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n\n\nclass_weights_dict = {class_num: weight for class_num, weight in zip(np.unique(y_train_encoded), class_weights)}\n\nprint(\"Class Weights Dictionary:\")\nprint(class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:30.844321Z","iopub.execute_input":"2023-12-14T06:55:30.844761Z","iopub.status.idle":"2023-12-14T06:55:30.859799Z","shell.execute_reply.started":"2023-12-14T06:55:30.844731Z","shell.execute_reply":"2023-12-14T06:55:30.858541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:30.861011Z","iopub.execute_input":"2023-12-14T06:55:30.861314Z","iopub.status.idle":"2023-12-14T06:55:30.867794Z","shell.execute_reply.started":"2023-12-14T06:55:30.861288Z","shell.execute_reply":"2023-12-14T06:55:30.866697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_1_model_fit\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Training Model ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=X_train.shape[1:], padding = 'same'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation=\"relu\", padding = 'same'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(256, (3, 3), activation=\"relu\", padding = 'same'))\nmodel.add(MaxPooling2D((2, 2)))\n\n# model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n# model.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\n\nmodel.add(Dense(60, activation=\"relu\"))\n\nmodel.add(Dense(80, activation=\"relu\"))\n\nmodel.add(Dense(120, activation=\"softmax\"))\n\nmodel.compile(optimizer=\"adam\", \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:30.869567Z","iopub.execute_input":"2023-12-14T06:55:30.869881Z","iopub.status.idle":"2023-12-14T06:55:30.981057Z","shell.execute_reply.started":"2023-12-14T06:55:30.869853Z","shell.execute_reply":"2023-12-14T06:55:30.979936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:30.990864Z","iopub.execute_input":"2023-12-14T06:55:30.991217Z","iopub.status.idle":"2023-12-14T06:55:31.026507Z","shell.execute_reply.started":"2023-12-14T06:55:30.991187Z","shell.execute_reply":"2023-12-14T06:55:31.025494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare call backs\nEarlyStop_callback = EarlyStopping(monitor='val_loss',mode = 'min', verbose = 1, patience=15, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:55:31.027936Z","iopub.execute_input":"2023-12-14T06:55:31.028359Z","iopub.status.idle":"2023-12-14T06:55:31.034147Z","shell.execute_reply.started":"2023-12-14T06:55:31.028313Z","shell.execute_reply":"2023-12-14T06:55:31.033128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train, validation_data=(X_test, y_test),\n          epochs=400, #validation_split = 0.1,\n          batch_size = 128, callbacks=my_callback, class_weight = class_weights_dict)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T06:55:31.035608Z","iopub.execute_input":"2023-12-14T06:55:31.036092Z","iopub.status.idle":"2023-12-14T06:56:42.746185Z","shell.execute_reply.started":"2023-12-14T06:55:31.036042Z","shell.execute_reply":"2023-12-14T06:56:42.745065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_1_model_evaluation\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Model Evaluation ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"pd.DataFrame(model.history.history).plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:56:42.749869Z","iopub.execute_input":"2023-12-14T06:56:42.750194Z","iopub.status.idle":"2023-12-14T06:56:43.141113Z","shell.execute_reply.started":"2023-12-14T06:56:42.750166Z","shell.execute_reply":"2023-12-14T06:56:43.140140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(\"loss: \", loss)\nprint(\"accuracy: \", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:56:43.142372Z","iopub.execute_input":"2023-12-14T06:56:43.142709Z","iopub.status.idle":"2023-12-14T06:56:43.496740Z","shell.execute_reply.started":"2023-12-14T06:56:43.142680Z","shell.execute_reply":"2023-12-14T06:56:43.495666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_train and y_test are one-hot encoded, convert them to indices\nif len(y_train.shape) > 1:\n    y_train_indices = np.argmax(y_train, axis=1)\nelse:\n    y_train_indices = y_train\n\nif len(y_test.shape) > 1:\n    y_test_indices = np.argmax(y_test, axis=1)\nelse:\n    y_test_indices = y_test\n\n\n# Get predicted labels for both training and test datasets\ntrain_pred_prob = model.predict(X_train)\ntest_pred_prob = model.predict(X_test)\n\ny_train_pred = np.argmax(train_pred_prob, axis=1)\ny_test_pred = np.argmax(test_pred_prob, axis=1)\n\n# Calculate confusion matrix and classification report for training dataset\nprint(\"Training Dataset:\")\nprint(confusion_matrix(y_train_indices, y_train_pred))\nprint(classification_report(y_train_indices, y_train_pred))\n\n# Calculate confusion matrix and classification report for test dataset\nprint(\"\\nTest Dataset:\")\nprint(confusion_matrix(y_test_indices, y_test_pred))\nprint(classification_report(y_test_indices, y_test_pred))\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T06:56:43.498298Z","iopub.execute_input":"2023-12-14T06:56:43.498699Z","iopub.status.idle":"2023-12-14T06:56:45.989737Z","shell.execute_reply.started":"2023-12-14T06:56:43.498663Z","shell.execute_reply":"2023-12-14T06:56:45.988710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test contains class labels directly (not one-hot encoded)\nn_classes = 120\ny_pred = model.predict(X_test)\n\n# Convert the predicted labels to probability scores (assuming a binary classification)\ny_pred_proba = np.max(y_pred, axis=1)\n\n# Convert y_test to one-hot encoded format if it's not already\ny_test_one_hot = label_binarize(y_test, classes=range(n_classes))\n\n# Calculate average precision for each class\naverage_precisions = []\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(n_classes):  # n_classes is the number of classes in your problem\n    precision, recall, _ = precision_recall_curve(y_test_one_hot[:, i], y_pred_proba)\n    average_precisions.append(average_precision_score(y_test_one_hot[:, i], y_pred_proba))\n\n    # Plot precision-recall curves for each class\n    plt.plot(recall, precision, lw=2, label=f'Class {i + 1} (AP = {average_precisions[i]:.2f})')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class (Multiclass)')\nplt.legend().set_visible(False)\nplt.show()\n\n# Create a DataFrame for the legend information\nlegend_data = {'Class': [f'Class {i + 1}' for i in range(n_classes)],\n               'Average Precision': average_precisions}\nlegend_df = pd.DataFrame(legend_data)\nlegend_df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:56:45.991318Z","iopub.execute_input":"2023-12-14T06:56:45.992340Z","iopub.status.idle":"2023-12-14T06:56:47.331567Z","shell.execute_reply.started":"2023-12-14T06:56:45.992288Z","shell.execute_reply":"2023-12-14T06:56:47.330494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_pred contains probabilities for each class\n# Threshold the probabilities to get class labels\nn_classes = 120\nthreshold = 0.5  # You can adjust this threshold based on your problem\ny_pred_labels = (y_pred > threshold).astype(int)\n\n# Binarize ground truth and predicted labels\ny_test_binary = label_binarize(y_test, classes=range(n_classes))\ny_pred_binary = label_binarize(y_pred_labels, classes=range(n_classes))\n\n# Calculate weighted-averaged precision, recall, and average precision\nmodel_precision = precision_score(y_test_binary, y_pred_binary, average='weighted')\nmodel_recall = recall_score(y_test_binary, y_pred_binary, average='weighted')\nmodel_AP = average_precision_score(y_test_binary, y_pred_binary, average='weighted')\n\nprint(f'Weighted-Averaged Precision: {model_precision:.2f}')\nprint(f'Weighted-Averaged Recall: {model_recall:.2f}')\nprint(f'Weighted-Averaged AP: {model_AP:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:56:47.333105Z","iopub.execute_input":"2023-12-14T06:56:47.333477Z","iopub.status.idle":"2023-12-14T06:56:47.456628Z","shell.execute_reply.started":"2023-12-14T06:56:47.333425Z","shell.execute_reply":"2023-12-14T06:56:47.455578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X,y","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:56:47.457918Z","iopub.execute_input":"2023-12-14T06:56:47.458237Z","iopub.status.idle":"2023-12-14T06:56:47.463418Z","shell.execute_reply.started":"2023-12-14T06:56:47.458209Z","shell.execute_reply":"2023-12-14T06:56:47.462275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2\"></a>\n# <p style=\"background-color:#FF6961; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® PART - 2 ( Feature Extractor - Transfer Learning ) ‚ú®</p>\n\n","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"_teyk4ESTyGE"}},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">\n    Content\n  </h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#part_2_model_download\" role=\"tab\" aria-controls=\"profile\">\n    Downloading Models\n    <span class=\"badge badge-primary badge-pill\">1</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#part_2_model_1\" role=\"tab\" aria-controls=\"messages\">\n    1 Model 1\n    <span class=\"badge badge-primary badge-pill\">2</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_1_train\" role=\"tab\" aria-controls=\"settings\">\n    1.1 Train - Test Split\n    <span class=\"badge badge-primary badge-pill\">3</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_1_class\" role=\"tab\" aria-controls=\"settings\">\n    1.2 Class Weight\n    <span class=\"badge badge-primary badge-pill\">4</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_1_fit\" role=\"tab\" aria-controls=\"settings\">\n    1.3 Training Model\n    <span class=\"badge badge-primary badge-pill\">5</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_1_evaluation\" role=\"tab\" aria-controls=\"settings\">\n    1.4 Model Evaluation\n    <span class=\"badge badge-primary badge-pill\">6</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_2_train\" role=\"tab\" aria-controls=\"settings\">\n    2.1 Train - Test Split\n    <span class=\"badge badge-primary badge-pill\">7</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_2_class\" role=\"tab\" aria-controls=\"settings\">\n    2.2 Class Weight\n    <span class=\"badge badge-primary badge-pill\">8</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_2_fit\" role=\"tab\" aria-controls=\"settings\">\n    2.3 Training Model\n    <span class=\"badge badge-primary badge-pill\">9</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_2_evaluation\" role=\"tab\" aria-controls=\"settings\">\n    2.4 Model Evaluation\n    <span class=\"badge badge-primary badge-pill\">10</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_3_train\" role=\"tab\" aria-controls=\"settings\">\n    3.1 Train - Test Split\n    <span class=\"badge badge-primary badge-pill\">11</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_3_class\" role=\"tab\" aria-controls=\"settings\">\n    3.2 Class Weight\n    <span class=\"badge badge-primary badge-pill\">12</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_3_fit\" role=\"tab\" aria-controls=\"settings\">\n    3.3 Training Model\n    <span class=\"badge badge-primary badge-pill\">13</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_3_evaluation\" role=\"tab\" aria-controls=\"settings\">\n    3.4 Model Evaluation\n    <span class=\"badge badge-primary badge-pill\">14</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_4_train\" role=\"tab\" aria-controls=\"settings\">\n    4.1 Train - Test Split\n    <span class=\"badge badge-primary badge-pill\">15</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_4_class\" role=\"tab\" aria-controls=\"settings\">\n    4.2 Class Weight\n    <span class=\"badge badge-primary badge-pill\">16</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_4_fit\" role=\"tab\" aria-controls=\"settings\">\n    4.3 Training Model\n    <span class=\"badge badge-primary badge-pill\">17</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_4_evaluation\" role=\"tab\" aria-controls=\"settings\">\n    4.4 Model Evaluation\n    <span class=\"badge badge-primary badge-pill\">18</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_5_train\" role=\"tab\" aria-controls=\"settings\">\n    5.1 Train - Test Split\n    <span class=\"badge badge-primary badge-pill\">19</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_5_class\" role=\"tab\" aria-controls=\"settings\">\n    5.2 Class Weight\n    <span class=\"badge badge-primary badge-pill\">20</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_5_fit\" role=\"tab\" aria-controls=\"settings\">\n    5.3 Training Model\n    <span class=\"badge badge-primary badge-pill\">21</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_5_evaluation\" role=\"tab\" aria-controls=\"settings\">\n    5.4 Model Evaluation\n    <span class=\"badge badge-primary badge-pill\">22</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_6_train\" role=\"tab\" aria-controls=\"settings\">\n    6.1 Train - Test Split\n    <span class=\"badge badge-primary badge-pill\">23</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_6_class\" role=\"tab\" aria-controls=\"settings\">\n    6.2 Class Weight\n    <span class=\"badge badge-primary badge-pill\">24</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_6_fit\" role=\"tab\" aria-controls=\"settings\">\n    6.3 Training Model\n    <span class=\"badge badge-primary badge-pill\">25</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_6_evaluation\" role=\"tab\" aria-controls=\"settings\">\n    6.4 Model Evaluation\n    <span class=\"badge badge-primary badge-pill\">26</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_7_train\" role=\"tab\" aria-controls=\"settings\">\n    7.1 Train - Test Split\n    <span class=\"badge badge-primary badge-pill\">27</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_7_class\" role=\"tab\" aria-controls=\"settings\">\n    7.2 Class Weight\n    <span class=\"badge badge-primary badge-pill\">28</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_7_fit\" role=\"tab\" aria-controls=\"settings\">\n    7.3 Training Model\n    <span class=\"badge badge-primary badge-pill\">29</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_7_evaluation\" role=\"tab\" aria-controls=\"settings\">\n    7.4 Model Evaluation\n    <span class=\"badge badge-primary badge-pill\">30</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_model_comparison\" role=\"tab\" aria-controls=\"settings\">\n    Model Comparison\n    <span class=\"badge badge-primary badge-pill\">31</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#part_2_prediction\" role=\"tab\" aria-controls=\"settings\">\n    Prediction\n    <span class=\"badge badge-primary badge-pill\">32</span>\n  </a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#summary\" role=\"tab\" aria-controls=\"settings\">\n    Summary\n    <span class=\"badge badge-primary badge-pill\">33</span>\n  </a>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"![image.png](https://miro.medium.com/v2/resize:fit:1400/1*QEmCZtruuWwtEOUzew2D4A.png)\n[Credit](https://www.google.com/url?sa=i&url=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-extraction-techniques-d619b56e31be&psig=AOvVaw3vSLYqQQXnYgT5DjwB93fm&ust=1701605368335000&source=images&cd=vfe&opi=89978449&ved=0CBIQjRxqFwoTCIj1tJLc8IIDFQAAAAAdAAAAABAD)","metadata":{}},{"cell_type":"code","source":"def get_num_files(path):\n    '''\n    Counts the number of files in a folder.\n    '''\n    if not os.path.exists(path):\n        return 0\n    return sum([len(files) for r, d, files in os.walk(path)])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:56:47.464620Z","iopub.execute_input":"2023-12-14T06:56:47.464946Z","iopub.status.idle":"2023-12-14T06:56:47.474299Z","shell.execute_reply.started":"2023-12-14T06:56:47.464919Z","shell.execute_reply":"2023-12-14T06:56:47.473275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os, cv2, random, time, shutil, csv\n#Data Paths\ntrain_dir = '/kaggle/input/dog-breed-identification/train'\ntest_dir = '/kaggle/input/dog-breed-identification/test'\n#Count/Print train and test samples.\ndata_size = get_num_files(train_dir)\ntest_size = get_num_files(test_dir)\nprint('Data samples size: ', data_size)\nprint('Test samples size: ', test_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:56:47.475554Z","iopub.execute_input":"2023-12-14T06:56:47.475858Z","iopub.status.idle":"2023-12-14T06:57:01.980629Z","shell.execute_reply.started":"2023-12-14T06:56:47.475810Z","shell.execute_reply":"2023-12-14T06:57:01.979432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read train labels.\nlabels_dataframe = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\n#Read sample_submission file to be modified by pridected labels.\nsample_df = pd.read_csv('/kaggle/input/dog-breed-identification/sample_submission.csv')\n#Incpect labels_dataframe.\nlabels_dataframe.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:57:01.981873Z","iopub.execute_input":"2023-12-14T06:57:01.982186Z","iopub.status.idle":"2023-12-14T06:57:02.577897Z","shell.execute_reply.started":"2023-12-14T06:57:01.982160Z","shell.execute_reply":"2023-12-14T06:57:02.576795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:57:02.579249Z","iopub.execute_input":"2023-12-14T06:57:02.579567Z","iopub.status.idle":"2023-12-14T06:57:02.650569Z","shell.execute_reply.started":"2023-12-14T06:57:02.579540Z","shell.execute_reply":"2023-12-14T06:57:02.649505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create list of alphabetically sorted labels.\ndog_breeds = sorted(list(set(labels_dataframe['breed'])))\nn_classes = len(dog_breeds)\nprint(n_classes)\ndog_breeds[:5]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:57:02.652073Z","iopub.execute_input":"2023-12-14T06:57:02.653075Z","iopub.status.idle":"2023-12-14T06:57:02.663276Z","shell.execute_reply.started":"2023-12-14T06:57:02.653033Z","shell.execute_reply":"2023-12-14T06:57:02.662293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Map each label string to an integer label.\nclass_to_num = dict(zip(dog_breeds, range(n_classes)))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:57:02.665074Z","iopub.execute_input":"2023-12-14T06:57:02.665433Z","iopub.status.idle":"2023-12-14T06:57:02.672584Z","shell.execute_reply.started":"2023-12-14T06:57:02.665388Z","shell.execute_reply":"2023-12-14T06:57:02.671511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def images_to_array(data_dir, labels_dataframe, img_size = (224,224,3)):\n    '''\n    1- Read image samples from certain directory.\n    2- Risize it, then stack them into one big numpy array.\n    3- Read sample's label form the labels dataframe.\n    4- One hot encode labels array.\n    5- Shuffle Data and label arrays.\n    '''\n    images_names = labels_dataframe['id']\n    images_labels = labels_dataframe['breed']\n    data_size = len(images_names)\n    #initailize output arrays.\n    X = np.zeros([data_size, img_size[0], img_size[1], img_size[2]], dtype=np.uint8)\n    y = np.zeros([data_size,1], dtype=np.uint8)\n    #read data and lables.\n    for i in tqdm(range(data_size)):\n        image_name = images_names[i]\n        img_dir = os.path.join(data_dir, image_name+'.jpg')\n        img_pixels = load_img(img_dir, target_size=img_size)\n        X[i] = img_pixels\n        \n        image_breed = images_labels[i]\n        y[i] = class_to_num[image_breed]\n    \n    #One hot encoder\n    y = to_categorical(y)\n    #shuffle    \n    ind = np.random.permutation(data_size)\n    X = X[ind]\n    y = y[ind]\n    print('Ouptut Data Size: ', X.shape)\n    print('Ouptut Label Size: ', y.shape)\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:57:02.674010Z","iopub.execute_input":"2023-12-14T06:57:02.674403Z","iopub.status.idle":"2023-12-14T06:57:02.690077Z","shell.execute_reply.started":"2023-12-14T06:57:02.674366Z","shell.execute_reply":"2023-12-14T06:57:02.688915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.preprocessing.image import load_img\n# from tqdm import tqdm\n# from keras.utils import to_categorical\n\nimg_size = (300,300, 3)\nX, y = images_to_array(train_dir, labels_dataframe, img_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:57:02.691518Z","iopub.execute_input":"2023-12-14T06:57:02.691939Z","iopub.status.idle":"2023-12-14T06:57:29.414699Z","shell.execute_reply.started":"2023-12-14T06:57:02.691902Z","shell.execute_reply":"2023-12-14T06:57:29.413662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_download\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Downloading Models ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"def get_features(model_name, data_preprocessor, input_size, data):\n    '''\n    1- Create a feature extractor to extract features from the data.\n    2- Returns the extracted features and the feature extractor.\n    '''\n    #Prepare pipeline.\n    input_layer = Input(input_size)\n    preprocessor = Lambda(data_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, batch_size=64, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:57:29.415815Z","iopub.execute_input":"2023-12-14T06:57:29.416077Z","iopub.status.idle":"2023-12-14T06:57:29.423252Z","shell.execute_reply.started":"2023-12-14T06:57:29.416054Z","shell.execute_reply":"2023-12-14T06:57:29.422269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<a id=\"inceptionv3\"></a>\n\n<div style=\"border-radius: 10px; border: 1px solid black; background-color:white ; font-size: 100%; text-align: left; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); padding: 10px; margin-bottom: 20px;\">\n    <h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: white; background-color: red; padding: 10px; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">üåü InceptionV3 Model üåü</h2>\n    <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*5Oj_rquiiX0Y-Frntj5t8A.jpeg\" alt=\"InceptionV3 Architecture\" style=\"width: 70%; display: block; margin: auto; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p>\n        <strong style=\"color: black;\">InceptionV3</strong> is a convolutional neural network (CNN) architecture developed by Google and introduced by Christian Szegedy and his team in 2015. Its name comes from the \"inception\" idea, combining different-sized convolutional layers to capture complex features.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Model Architecture:</strong> InceptionV3 has an architecture consisting of 48 layers designed for complex visual recognition tasks. It incorporates convolutional layers of various sizes and parallel blocks, allowing the model to capture features at different scales.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Training and Data:</strong> The model is trained on a large amount of general visual data, typically using the ImageNet dataset. InceptionV3 is commonly trained on a dataset consisting of 1,281,167 images across 1000 classes.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Applications:</strong> InceptionV3 is successfully used in tasks such as object recognition, transfer learning, and feature extraction. It has become a popular choice for solving image classification problems.\n    </p>\n</div>\n\nPhoto Credit: [Medium](https://medium.com/@AnasBrital98/inception-v3-cnn-architecture-explained-691cfb7bba08)","metadata":{}},{"cell_type":"code","source":"# Extract features using InceptionV3 as extractor.\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D, Lambda, Dropout, InputLayer, Input\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_preprocessor = preprocess_input\ninception_features = get_features(InceptionV3,\n                                  inception_preprocessor,\n                                  img_size, X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:57:29.424505Z","iopub.execute_input":"2023-12-14T06:57:29.424789Z","iopub.status.idle":"2023-12-14T06:58:04.081764Z","shell.execute_reply.started":"2023-12-14T06:57:29.424755Z","shell.execute_reply":"2023-12-14T06:58:04.080624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"xception\"></a>\n\n<div style=\"border-radius: 10px; border: 1px solid black; background-color:white ; font-size: 100%; text-align: left; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); padding: 10px; margin-bottom: 20px;\">\n    <h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: white; background-color: red; padding: 10px; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">üåü Xception Model üåü</h2>\n    <img src=\"https://3065708918-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-LRrOFNeUGLZef_2NLZ0%2F-LeEDJgZ_Xj2uTEbaYKT%2F-LeEHZndr-UWea8jfQP8%2Fxception1.jpg?alt=media&token=d2a19b1a-1b5b-410d-90a5-7a5a993fe026\" alt=\"InceptionV3 Architecture\" style=\"width: 70%; display: block; margin: auto; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p>\n        <strong style=\"color: black;\">Xception</strong> is a convolutional neural network (CNN) architecture introduced by Google Research. It was proposed by Fran√ßois Chollet, the creator of Keras, in 2017. Xception is known for its depthwise separable convolutions, which aim to capture both global and local dependencies in the data.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Model Architecture:</strong> Xception's architecture is based on the idea of depthwise separable convolutions, which significantly reduces the number of parameters compared to traditional convolutional layers. It consists of 71 layers, including depthwise separable convolutions, skip connections, and linear mappings.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Training and Data:</strong> Xception is trained on large-scale visual datasets, often using the ImageNet dataset. This dataset contains a vast collection of images across 1000 classes, providing the model with a diverse set of visual features to learn from.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Applications:</strong> Xception is widely used for various computer vision tasks, including image classification, object detection, and feature extraction. Its efficiency in terms of computational resources makes it suitable for both research and practical applications.\n    </p>\n</div>\n\nPhoto Credit: [Gitbook](https://stephan-osterburg.gitbook.io/coding/coding/ml-dl/tensorfow/ch3-xception/xception-architectural-design)","metadata":{}},{"cell_type":"code","source":"# Extract features using Xception as extractor.\nfrom keras.applications.xception import Xception, preprocess_input\nxception_preprocessor = preprocess_input\nxception_features = get_features(Xception,\n                                 xception_preprocessor,\n                                 img_size, X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:58:04.082986Z","iopub.execute_input":"2023-12-14T06:58:04.083276Z","iopub.status.idle":"2023-12-14T06:58:55.994945Z","shell.execute_reply.started":"2023-12-14T06:58:04.083251Z","shell.execute_reply":"2023-12-14T06:58:55.993962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"nasnetlarge\"></a>\n\n<div style=\"border-radius: 10px; border: 1px solid black; background-color:white ; font-size: 100%; text-align: left; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); padding: 10px; margin-bottom: 20px;\">\n    <h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: white; background-color: red; padding: 10px; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">üåü NASNetLarge Model üåü</h2>\n    <img src=\"https://pub.mdpi-res.com/diagnostics/diagnostics-10-01064/article_deploy/html/images/diagnostics-10-01064-g003.png?1607573508https://3065708918-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-LRrOFNeUGLZef_2NLZ0%2F-LeEDJgZ_Xj2uTEbaYKT%2F-LeEHZndr-UWea8jfQP8%2Fnasnet_large.jpg?alt=media&token=344524a4-869b-45c4-9b6b-8112a5c579db\" alt=\"NASNetLarge Architecture\" style=\"width: 70%; display: block; margin: auto; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p>\n        <strong style=\"color: black;\">NASNetLarge</strong> is a convolutional neural network (CNN) architecture designed by Google Research. NASNet, short for Neural Architecture Search Network, utilizes reinforcement learning to design efficient and effective neural network architectures. NASNetLarge is one of the variations with a larger number of parameters, suitable for tasks requiring high-capacity models.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Model Architecture:</strong> NASNetLarge's architecture is the result of an automated architecture search process. It is known for its hierarchical structure and repeated motifs. The architecture is designed to capture complex patterns and features in visual data.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Training and Data:</strong> NASNetLarge is typically trained on large-scale visual datasets, including the ImageNet dataset. The training process involves reinforcement learning techniques to discover optimal architectures. The model learns from diverse visual data, allowing it to generalize well to various tasks.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Applications:</strong> NASNetLarge is applied to tasks such as image classification, object detection, and feature extraction. Its architecture's flexibility and efficiency make it suitable for a wide range of computer vision applications.\n    </p>\n</div>\n\nPhoto Credit: [MDPI](https://www.mdpi.com/2075-4418/10/12/1064)\n","metadata":{}},{"cell_type":"code","source":"# Extract features using NASNetLarge as extractor.\nfrom keras.applications.nasnet import NASNetLarge, preprocess_input\nnasnet_preprocessor = preprocess_input\nnasnet_features = get_features(NASNetLarge,\n                               nasnet_preprocessor,\n                               img_size, X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T06:58:55.996228Z","iopub.execute_input":"2023-12-14T06:58:55.996561Z","iopub.status.idle":"2023-12-14T07:01:50.349689Z","shell.execute_reply.started":"2023-12-14T06:58:55.996535Z","shell.execute_reply":"2023-12-14T07:01:50.348621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"inceptionresnetv2\"></a>\n\n<div style=\"border-radius: 10px; border: 1px solid black; background-color:white ; font-size: 100%; text-align: left; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); padding: 10px; margin-bottom: 20px;\">\n    <h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: white; background-color: red; padding: 10px; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">üåü InceptionResNetV2 Model üåü</h2>\n    <img src=\"https://www.researchgate.net/publication/327425789/figure/fig3/AS:667190047027201@1536081911884/A-modified-version-of-Inception-ResNet-V2-Szegedy-et-al-2016-was-used-as-the.ppm\" alt=\"InceptionResNetV2 Architecture\" style=\"width: 70%; display: block; margin: auto; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p>\n        <strong style=\"color: black;\">InceptionResNetV2</strong> is a sophisticated convolutional neural network (CNN) architecture that blends concepts from Inception and ResNet. It was introduced by Google Research and is known for its ability to capture intricate features in visual data.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Model Architecture:</strong> The architecture of InceptionResNetV2 incorporates the strengths of both Inception and ResNet. It includes inception modules for feature extraction and residual connections for addressing the vanishing gradient problem. The result is a deep and efficient model capable of handling complex tasks.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Training and Data:</strong> InceptionResNetV2 is trained on large-scale visual datasets, commonly using the ImageNet dataset. The training process involves optimizing a diverse set of parameters to capture hierarchical features. The model benefits from the extensive and varied data in the training set.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Applications:</strong> InceptionResNetV2 is utilized for a range of computer vision tasks, including image classification, object detection, and feature extraction. Its architecture's combination of inception and residual modules makes it well-suited for handling intricate visual patterns.\n    </p>\n</div>\n\nPhoto Credit: [ResearchGate](https://www.researchgate.net/figure/A-modified-version-of-Inception-ResNet-V2-Szegedy-et-al-2016-was-used-as-the_fig3_327425789)\n","metadata":{}},{"cell_type":"code","source":"# Extract features using InceptionResNetV2 as extractor.\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\ninc_resnet_preprocessor = preprocess_input\ninc_resnet_features = get_features(InceptionResNetV2,\n                                   inc_resnet_preprocessor,\n                                   img_size, X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:01:50.351493Z","iopub.execute_input":"2023-12-14T07:01:50.351898Z","iopub.status.idle":"2023-12-14T07:03:01.076483Z","shell.execute_reply.started":"2023-12-14T07:01:50.351860Z","shell.execute_reply":"2023-12-14T07:03:01.075336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<a id=\"vgg16\"></a>\n\n<div style=\"border-radius: 10px; border: 1px solid black; background-color:white ; font-size: 100%; text-align: left; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); padding: 10px; margin-bottom: 20px;\">\n    <h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: white; background-color: red; padding: 10px; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">üåü VGG16 Model üåü</h2>\n    <img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200219152207/new41.jpg\" alt=\"VGG16 Architecture\" style=\"width: 70%; display: block; margin: auto; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p>\n        <strong style=\"color: black;\">VGG16</strong> is a convolutional neural network (CNN) architecture designed by the Visual Graphics Group (VGG) at the University of Oxford. It was introduced by Simonyan and Zisserman in 2014. VGG16 is known for its simplicity and uniform architecture, featuring small-sized convolutional filters.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Model Architecture:</strong> VGG16's architecture consists of 16 weight layers, including 13 convolutional layers and 3 fully connected layers. The convolutional layers use small 3x3 filters, and the max-pooling layers follow each group of convolutional layers. The architecture is straightforward and easy to understand.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Training and Data:</strong> VGG16 is typically trained on large-scale visual datasets, with the ImageNet dataset being a common choice. The training process involves optimizing the network's weights to classify a diverse set of images across 1000 classes. The extensive data in ImageNet contributes to the model's ability to recognize various visual patterns.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Applications:</strong> VGG16 is widely used for image classification tasks. Its architecture's simplicity and effectiveness make it a popular choice for various computer vision applications. Transfer learning with VGG16 is also common in projects with limited labeled data.\n    </p>\n</div>\n\nPhoto Credit: [GeeksforGeeks](https://www.geeksforgeeks.org/vgg-16-cnn-model/)","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\nvgg16_preprocessor = preprocess_input\nvgg16_features = get_features(VGG16,\n                                   vgg16_preprocessor,\n                                   img_size, X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:03:01.078100Z","iopub.execute_input":"2023-12-14T07:03:01.079043Z","iopub.status.idle":"2023-12-14T07:03:53.587555Z","shell.execute_reply.started":"2023-12-14T07:03:01.079002Z","shell.execute_reply":"2023-12-14T07:03:53.586425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<a id=\"resnet50\"></a>\n\n<div style=\"border-radius: 10px; border: 1px solid black; background-color:white ; font-size: 100%; text-align: left; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); padding: 10px; margin-bottom: 20px;\">\n    <h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: white; background-color: red; padding: 10px; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">üåü ResNet50 Model üåü</h2>\n    <img src=\"https://miro.medium.com/v2/resize:fit:1400/0*tH9evuOFqk8F41FG.png\" alt=\"ResNet50 Architecture\" style=\"width: 70%; display: block; margin: auto; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p>\n        <strong style=\"color: black;\">ResNet50</strong> is a convolutional neural network (CNN) architecture that belongs to the ResNet family. It was introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun in 2015. ResNet50 is known for its deep structure and the use of residual blocks, allowing the training of very deep networks.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Model Architecture:</strong> ResNet50's architecture includes 48 convolutional layers along with max-pooling, fully connected, and softmax layers. The key innovation is the use of residual blocks, where shortcut connections skip one or more layers. This helps in mitigating the vanishing gradient problem during training.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Training and Data:</strong> ResNet50 is typically trained on large datasets like ImageNet. The training process involves adjusting millions of parameters to recognize a diverse set of images across 1000 classes. The deep architecture allows the model to capture intricate features and patterns in visual data.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Applications:</strong> ResNet50 is widely used for image classification, object detection, and feature extraction tasks. Its deep structure and the use of residual connections make it effective in handling complex visual patterns. Transfer learning with pre-trained ResNet50 models is common in various computer vision applications.\n    </p>\n</div>\n\nPhoto Credit: [TowardsDataScience](https://towardsdatascience.com/the-annotated-resnet-50-a6c536034758)","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input\n\nresnet50_preprocessor = preprocess_input\nresnet50_features = get_features(ResNet50,\n                                   resnet50_preprocessor,\n                                   img_size, X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:03:53.589090Z","iopub.execute_input":"2023-12-14T07:03:53.589411Z","iopub.status.idle":"2023-12-14T07:04:33.653478Z","shell.execute_reply.started":"2023-12-14T07:03:53.589382Z","shell.execute_reply":"2023-12-14T07:04:33.652346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"mobilenetv2\"></a>\n\n<div style=\"border-radius: 10px; border: 1px solid black; background-color:white ; font-size: 100%; text-align: left; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); padding: 10px; margin-bottom: 20px;\">\n    <h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: white; background-color: red; padding: 10px; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">üåü MobileNetV2 Model üåü</h2>\n    <img src=\"https://www.researchgate.net/publication/350152088/figure/fig1/AS:1002717703045121@1616077938892/The-proposed-MobileNetV2-network-architecture.png\" alt=\"MobileNetV2 Architecture\" style=\"width: 70%; display: block; margin: auto; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p>\n        <strong style=\"color: black;\">MobileNetV2</strong> is a lightweight convolutional neural network (CNN) architecture designed for mobile and edge devices. It was introduced by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen in 2018. MobileNetV2 aims to provide efficient and fast inference while maintaining good accuracy.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Model Architecture:</strong> MobileNetV2's architecture incorporates inverted residuals and linear bottlenecks to build a more efficient model. It uses depthwise separable convolutions, which significantly reduces the number of parameters and computational cost. The model includes shortcut connections to facilitate information flow.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Training and Data:</strong> MobileNetV2 is trained on large-scale datasets like ImageNet. The training process involves optimizing the model's parameters to recognize a diverse set of images across various classes. The emphasis is on achieving a good trade-off between model size, speed, and accuracy.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Applications:</strong> MobileNetV2 is suitable for applications where computational resources are limited, such as mobile devices and embedded systems. It is often used for image classification, object detection, and other computer vision tasks on resource-constrained platforms.\n    </p>\n</div>\n\nPhoto Credit: [ResearchGate](https://www.researchgate.net/figure/The-proposed-MobileNetV2-network-architecture_fig1_350152088)","metadata":{}},{"cell_type":"code","source":"from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nmobilenet_v2_preprocessor = preprocess_input\nmobilenet_v2_features = get_features(MobileNetV2,\n                                     mobilenet_v2_preprocessor,\n                                     img_size, X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:04:33.655119Z","iopub.execute_input":"2023-12-14T07:04:33.655920Z","iopub.status.idle":"2023-12-14T07:04:56.694098Z","shell.execute_reply.started":"2023-12-14T07:04:33.655878Z","shell.execute_reply":"2023-12-14T07:04:56.693042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"densenet121\"></a>\n\n<div style=\"border-radius: 10px; border: 1px solid black; background-color:white ; font-size: 100%; text-align: left; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); padding: 10px; margin-bottom: 20px;\">\n    <h2 style=\"border: 0; border-radius: 15px; font-weight: bold; font-size: 220%; color: white; background-color: red; padding: 10px; text-align: center; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">üåü DenseNet121 Model üåü</h2>\n    <img src=\"https://www.researchgate.net/publication/334170752/figure/fig5/AS:776225345785857@1562077952441/A-schematic-illustration-of-the-DenseNet-121-architecture-82.png\" alt=\"DenseNet121 Architecture\" style=\"width: 70%; display: block; margin: auto; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p>\n        <strong style=\"color: black;\">DenseNet121</strong> is a convolutional neural network (CNN) architecture that utilizes a dense connectivity pattern. It was introduced by Gao Huang, Zhuang Liu, and Laurens van der Maaten in 2017. DenseNet121 is known for its efficient use of parameters and feature reuse across layers.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Model Architecture:</strong> DenseNet121 employs a dense block structure where each layer is connected to every other layer in a feed-forward fashion. This dense connectivity enables feature reuse, reduces the number of parameters, and enhances information flow throughout the network. It consists of multiple dense blocks separated by transition layers.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Training and Data:</strong> DenseNet121 is trained on large-scale visual datasets, often using the ImageNet dataset. The training process involves optimizing the model's parameters to recognize a diverse set of images across multiple classes. DenseNet121 benefits from its dense connectivity pattern to capture intricate features.\n    </p>\n    <p>\n        <strong style=\"color: black;\">Applications:</strong> DenseNet121 is widely used for tasks such as image classification, object detection, and feature extraction. Its efficient use of parameters and feature reuse make it suitable for applications where computational resources are a consideration.\n    </p>\n</div>\n\nPhoto Credit: [ResearchGate](https://www.researchgate.net/figure/A-schematic-illustration-of-the-DenseNet-121-architecture-82_fig5_334170752)","metadata":{}},{"cell_type":"code","source":"from keras.applications.densenet import DenseNet121, preprocess_input\ndensenet_preprocessor = preprocess_input\ndensenet_features = get_features(DenseNet121,\n                                 densenet_preprocessor,\n                                 img_size, X)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:04:56.695719Z","iopub.execute_input":"2023-12-14T07:04:56.696420Z","iopub.status.idle":"2023-12-14T07:05:40.068922Z","shell.execute_reply.started":"2023-12-14T07:04:56.696380Z","shell.execute_reply":"2023-12-14T07:05:40.067898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#It's a good habit to free up some RAM memory.\n#X variable won't be needed anymore, so let's get rid of it.\ndel X","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:05:40.071348Z","iopub.execute_input":"2023-12-14T07:05:40.071711Z","iopub.status.idle":"2023-12-14T07:05:40.082390Z","shell.execute_reply.started":"2023-12-14T07:05:40.071681Z","shell.execute_reply":"2023-12-14T07:05:40.081228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_1\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Model - 1 ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"final_features = np.concatenate([inception_features,\n                                 xception_features,\n                                 nasnet_features,\n                                 inc_resnet_features,], axis=-1)\nprint('Final feature maps shape', final_features.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:05:40.083703Z","iopub.execute_input":"2023-12-14T07:05:40.083997Z","iopub.status.idle":"2023-12-14T07:05:40.273095Z","shell.execute_reply.started":"2023-12-14T07:05:40.083971Z","shell.execute_reply":"2023-12-14T07:05:40.272083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_1_train\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 1.1 Train - Test Split ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"original_value_counts = pd.Series(y.argmax(axis=1)).value_counts(normalize=True)\n\nX_train, X_test, y_train, y_test = train_test_split(final_features, y, test_size=0.1, stratify=y, random_state=42)\n\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\ntrain_value_counts = pd.Series(y_train_indices).value_counts(normalize=True)\ntest_value_counts = pd.Series(y_test_indices).value_counts(normalize=True)\n\nfig, ax = plt.subplots(figsize=(20, 20))\n\nbar_width = 0.2\nindex = np.arange(len(original_value_counts))\n\nbar1 = ax.barh(index, original_value_counts, bar_width, label='Main Data')\nbar2 = ax.barh(index, train_value_counts, bar_width, label='Train Set', left=original_value_counts)\nbar4 = ax.barh(index, test_value_counts, bar_width, label='Test Set', left=original_value_counts + train_value_counts)\n\nax.set_xlabel('Percentages')\nax.set_title('Class Distribution')\nax.set_yticks(index)\nax.set_yticklabels(original_value_counts.index)\nax.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:05:40.274414Z","iopub.execute_input":"2023-12-14T07:05:40.275256Z","iopub.status.idle":"2023-12-14T07:05:43.766256Z","shell.execute_reply.started":"2023-12-14T07:05:40.275214Z","shell.execute_reply":"2023-12-14T07:05:43.765225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_1_class\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 1.2 Class Weight ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(np.argmax(y_train, axis=1))\n\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n\nclass_weights_dict = {class_num: weight for class_num, weight in zip(np.unique(y_train_encoded), class_weights)}\n\nprint(\"Class Weights Dictionary:\")\nprint(class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:05:43.767600Z","iopub.execute_input":"2023-12-14T07:05:43.767933Z","iopub.status.idle":"2023-12-14T07:05:43.785779Z","shell.execute_reply.started":"2023-12-14T07:05:43.767904Z","shell.execute_reply":"2023-12-14T07:05:43.784622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 80\nepochs = 400","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:05:43.787198Z","iopub.execute_input":"2023-12-14T07:05:43.787593Z","iopub.status.idle":"2023-12-14T07:05:43.792585Z","shell.execute_reply.started":"2023-12-14T07:05:43.787558Z","shell.execute_reply":"2023-12-14T07:05:43.791526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_1_fit\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 1.3 Training Model ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"#Prepare call backs\nEarlyStop_callback = EarlyStopping(monitor='val_recall', verbose=1,mode = 'max', patience=15, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:05:43.794018Z","iopub.execute_input":"2023-12-14T07:05:43.794392Z","iopub.status.idle":"2023-12-14T07:05:43.803503Z","shell.execute_reply.started":"2023-12-14T07:05:43.794358Z","shell.execute_reply":"2023-12-14T07:05:43.802496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare DNN model\nfrom keras.optimizers import Adam\n\nmodel_1 = keras.models.Sequential([\n    InputLayer(X_train.shape[1:]),\n    Dropout(0.7),\n    Dense(n_classes, activation='softmax', #kernel_regularizer=regularizers.l2(0.01)\n         )])\n\noptimizer = Adam(learning_rate = 0.0001)\nmodel_1.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['Recall'])\n\n#Train simple DNN on extracted features.\nhistory_1 = model_1.fit( #final_features, y,\n            X_train, y_train,\n            batch_size= batch_size,\n            epochs=epochs,\n            validation_data=(X_test, y_test),\n#             validation_split = 0.1,\n            callbacks=my_callback,\n            class_weight = class_weights_dict\n                       )","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:05:43.804631Z","iopub.execute_input":"2023-12-14T07:05:43.804943Z","iopub.status.idle":"2023-12-14T07:06:01.738895Z","shell.execute_reply.started":"2023-12-14T07:05:43.804916Z","shell.execute_reply":"2023-12-14T07:06:01.737873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_1_evaluation\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 1.4 Model Evaluation ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"loss, recall = model_1.evaluate(X_test, y_test, verbose=0)\nprint(\"loss: \", loss)\nprint(\"recall: \", recall)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:01.740500Z","iopub.execute_input":"2023-12-14T07:06:01.740918Z","iopub.status.idle":"2023-12-14T07:06:01.970259Z","shell.execute_reply.started":"2023-12-14T07:06:01.740878Z","shell.execute_reply":"2023-12-14T07:06:01.969287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_1","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:01.971617Z","iopub.execute_input":"2023-12-14T07:06:01.971930Z","iopub.status.idle":"2023-12-14T07:06:01.978204Z","shell.execute_reply.started":"2023-12-14T07:06:01.971902Z","shell.execute_reply":"2023-12-14T07:06:01.977153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_data = history_1.history\n\nloss_df_1 = pd.DataFrame(history_data)\nloss_df_1","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:01.979727Z","iopub.execute_input":"2023-12-14T07:06:01.980229Z","iopub.status.idle":"2023-12-14T07:06:01.999828Z","shell.execute_reply.started":"2023-12-14T07:06:01.980195Z","shell.execute_reply":"2023-12-14T07:06:01.998768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df_1.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:02.001105Z","iopub.execute_input":"2023-12-14T07:06:02.001486Z","iopub.status.idle":"2023-12-14T07:06:02.350884Z","shell.execute_reply.started":"2023-12-14T07:06:02.001451Z","shell.execute_reply":"2023-12-14T07:06:02.349938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:02.352240Z","iopub.execute_input":"2023-12-14T07:06:02.352576Z","iopub.status.idle":"2023-12-14T07:06:02.616388Z","shell.execute_reply.started":"2023-12-14T07:06:02.352547Z","shell.execute_reply":"2023-12-14T07:06:02.615407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.evaluate(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:02.617623Z","iopub.execute_input":"2023-12-14T07:06:02.617924Z","iopub.status.idle":"2023-12-14T07:06:04.380750Z","shell.execute_reply.started":"2023-12-14T07:06:02.617898Z","shell.execute_reply":"2023-12-14T07:06:04.379809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_train and y_test are one-hot encoded, convert them to indices\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\n# Get predicted labels for both training and test datasets\ntrain_pred_prob = model_1.predict(X_train)\ntest_pred_prob = model_1.predict(X_test)\n\ny_train_pred = np.argmax(train_pred_prob, axis=1)\ny_test_pred = np.argmax(test_pred_prob, axis=1)\n\n# Calculate confusion matrix and classification report for training dataset\nprint(\"Training Dataset:\")\nprint(confusion_matrix(y_train_indices, y_train_pred))\nprint(classification_report(y_train_indices, y_train_pred))\n\n# Calculate confusion matrix and classification report for test dataset\nprint(\"\\nTest Dataset:\")\nprint(confusion_matrix(y_test_indices, y_test_pred))\nprint(classification_report(y_test_indices, y_test_pred))\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:06:04.381898Z","iopub.execute_input":"2023-12-14T07:06:04.382219Z","iopub.status.idle":"2023-12-14T07:06:06.200163Z","shell.execute_reply.started":"2023-12-14T07:06:04.382194Z","shell.execute_reply":"2023-12-14T07:06:06.199037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test is in multilabel-indicator format\ny_pred_proba = model_1.predict(X_test)\n\n# Calculate average precision and area under the ROC curve for each class\naverage_precisions = []\nroc_aucs = []\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(n_classes):  # n_classes is the number of classes in your problem\n    precision, recall, _ = precision_recall_curve(y_test[:, i], y_pred_proba[:, i])\n    average_precisions.append(average_precision_score(y_test[:, i], y_pred_proba[:, i]))\n    roc_aucs.append(roc_auc_score(y_test[:, i], y_pred_proba[:, i]))\n\n    # Plot precision-recall curves for each class\n    plt.plot(recall, precision, lw=2, label=f'Class {i + 1} (AP = {average_precisions[i]:.2f}, AUC = {roc_aucs[i]:.2f})')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class')\nplt.show()\n\n# Create a DataFrame for the legend information\nlegend_data = {'Class': [f'Class {i + 1}' for i in range(n_classes)],\n               'Average Precision': average_precisions,\n               'AUC': roc_aucs}\nlegend_df = pd.DataFrame(legend_data)\nlegend_df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:06.202027Z","iopub.execute_input":"2023-12-14T07:06:06.202429Z","iopub.status.idle":"2023-12-14T07:06:07.675412Z","shell.execute_reply.started":"2023-12-14T07:06:06.202391Z","shell.execute_reply":"2023-12-14T07:06:07.674494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import precision_score, recall_score, average_precision_score\n# from sklearn.preprocessing import label_binarize\n\n# Assuming y_test_indices and y_test_pred are obtained as mentioned in your code\n# Convert to binary format\ny_test_binary = label_binarize(y_test_indices, classes=range(n_classes))\ny_pred_binary = label_binarize(y_test_pred, classes=range(n_classes))\n\n# Calculate precision, recall, and AP\nmodel1_precision = precision_score(y_test_binary, y_pred_binary, average='weighted')\nmodel1_recall = recall_score(y_test_binary, y_pred_binary, average='weighted')\nmodel1_AP = average_precision_score(y_test_binary, y_pred_binary, average='weighted')\n\nprint(f'Weighted-Averaged Precision: {model1_precision:.2f}')\nprint(f'Weighted-Averaged Recall: {model1_recall:.2f}')\nprint(f'Weighted-Averaged AP: {model1_AP:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:07.676685Z","iopub.execute_input":"2023-12-14T07:06:07.676977Z","iopub.status.idle":"2023-12-14T07:06:07.793840Z","shell.execute_reply.started":"2023-12-14T07:06:07.676952Z","shell.execute_reply":"2023-12-14T07:06:07.792783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_2\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Model - 2 ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"final_features_1 = np.concatenate([vgg16_features,\n                                 resnet50_features,\n                                 mobilenet_v2_features,\n                                 inc_resnet_features,], axis=-1)\nprint('Final feature maps shape', final_features_1.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:07.795144Z","iopub.execute_input":"2023-12-14T07:06:07.795572Z","iopub.status.idle":"2023-12-14T07:06:07.884637Z","shell.execute_reply.started":"2023-12-14T07:06:07.795533Z","shell.execute_reply":"2023-12-14T07:06:07.883645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_2_train\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 2.1 Train - Test Split ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"original_value_counts = pd.Series(y.argmax(axis=1)).value_counts(normalize=True)\n\nX_train, X_test, y_train, y_test = train_test_split(final_features_1, y, test_size=0.1, stratify=y, random_state=42)\n\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\ntrain_value_counts = pd.Series(y_train_indices).value_counts(normalize=True)\ntest_value_counts = pd.Series(y_test_indices).value_counts(normalize=True)\n\nfig, ax = plt.subplots(figsize=(20, 20))\n\nbar_width = 0.2\nindex = np.arange(len(original_value_counts))\n\nbar1 = ax.barh(index, original_value_counts, bar_width, label='Main Data')\nbar2 = ax.barh(index, train_value_counts, bar_width, label='Train Set', left=original_value_counts)\nbar4 = ax.barh(index, test_value_counts, bar_width, label='Test Set', left=original_value_counts + train_value_counts)\n\nax.set_xlabel('Percentages')\nax.set_title('Class Distribution')\nax.set_yticks(index)\nax.set_yticklabels(original_value_counts.index)\nax.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:07.886206Z","iopub.execute_input":"2023-12-14T07:06:07.886611Z","iopub.status.idle":"2023-12-14T07:06:11.412464Z","shell.execute_reply.started":"2023-12-14T07:06:07.886575Z","shell.execute_reply":"2023-12-14T07:06:11.411475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_2_class\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 2.2 Class Weight ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"# from sklearn.utils.class_weight import compute_class_weight\n# from sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(np.argmax(y_train, axis=1))\n\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n\nclass_weights_dict = {class_num: weight for class_num, weight in zip(np.unique(y_train_encoded), class_weights)}\n\nprint(\"Class Weights Dictionary:\")\nprint(class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:11.413966Z","iopub.execute_input":"2023-12-14T07:06:11.414239Z","iopub.status.idle":"2023-12-14T07:06:11.427650Z","shell.execute_reply.started":"2023-12-14T07:06:11.414215Z","shell.execute_reply":"2023-12-14T07:06:11.426653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_2_fit\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 2.3 Training Model ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"#Prepare call backs\nEarlyStop_callback = EarlyStopping(monitor='val_loss', verbose=1,mode = 'min', patience=15, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:11.428987Z","iopub.execute_input":"2023-12-14T07:06:11.429288Z","iopub.status.idle":"2023-12-14T07:06:11.434647Z","shell.execute_reply.started":"2023-12-14T07:06:11.429262Z","shell.execute_reply":"2023-12-14T07:06:11.433765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare DNN model\nmodel_2 = keras.models.Sequential([\n    InputLayer(X_train.shape[1:]),\n    Dropout(0.5),\n    Dense(n_classes, activation='softmax')\n])\n\nmodel_2.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['Recall'])\n\n#Train simple DNN on extracted features.\nhistory_2 = model_2.fit(X_train, y_train,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_data=(X_test, y_test),\n            callbacks=my_callback,\n            class_weight = class_weights_dict)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:06:11.435786Z","iopub.execute_input":"2023-12-14T07:06:11.436062Z","iopub.status.idle":"2023-12-14T07:06:22.475364Z","shell.execute_reply.started":"2023-12-14T07:06:11.436038Z","shell.execute_reply":"2023-12-14T07:06:22.474260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_2_evaluation\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 2.4 Model Evaluation ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"loss, recall = model_2.evaluate(X_test, y_test, verbose=0)\nprint(\"loss: \", loss)\nprint(\"recall: \", recall)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:22.476661Z","iopub.execute_input":"2023-12-14T07:06:22.476983Z","iopub.status.idle":"2023-12-14T07:06:22.635425Z","shell.execute_reply.started":"2023-12-14T07:06:22.476955Z","shell.execute_reply":"2023-12-14T07:06:22.634448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_2","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:22.636735Z","iopub.execute_input":"2023-12-14T07:06:22.637058Z","iopub.status.idle":"2023-12-14T07:06:22.643490Z","shell.execute_reply.started":"2023-12-14T07:06:22.637030Z","shell.execute_reply":"2023-12-14T07:06:22.642495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_data = history_2.history\n\nloss_df_2 = pd.DataFrame(history_data)\nloss_df_2","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:22.644559Z","iopub.execute_input":"2023-12-14T07:06:22.644857Z","iopub.status.idle":"2023-12-14T07:06:22.661734Z","shell.execute_reply.started":"2023-12-14T07:06:22.644821Z","shell.execute_reply":"2023-12-14T07:06:22.660782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df_2.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:22.663011Z","iopub.execute_input":"2023-12-14T07:06:22.663316Z","iopub.status.idle":"2023-12-14T07:06:23.035530Z","shell.execute_reply.started":"2023-12-14T07:06:22.663282Z","shell.execute_reply":"2023-12-14T07:06:23.034471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix, classification_report\n\n# Assuming y_train and y_test are one-hot encoded, convert them to indices\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\n# Get predicted labels for both training and test datasets\ntrain_pred_prob = model_2.predict(X_train)\ntest_pred_prob = model_2.predict(X_test)\n\ny_train_pred = np.argmax(train_pred_prob, axis=1)\ny_test_pred = np.argmax(test_pred_prob, axis=1)\n\n# Calculate confusion matrix and classification report for training dataset\nprint(\"Training Dataset:\")\nprint(confusion_matrix(y_train_indices, y_train_pred))\nprint(classification_report(y_train_indices, y_train_pred))\n\n# Calculate confusion matrix and classification report for test dataset\nprint(\"\\nTest Dataset:\")\nprint(confusion_matrix(y_test_indices, y_test_pred))\nprint(classification_report(y_test_indices, y_test_pred))\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:06:23.036802Z","iopub.execute_input":"2023-12-14T07:06:23.037132Z","iopub.status.idle":"2023-12-14T07:06:24.362954Z","shell.execute_reply.started":"2023-12-14T07:06:23.037104Z","shell.execute_reply":"2023-12-14T07:06:24.361945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test is in multilabel-indicator format\ny_pred_proba = model_2.predict(X_test)\n\n# Calculate average precision and area under the ROC curve for each class\naverage_precisions = []\nroc_aucs = []\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(n_classes):  # n_classes is the number of classes in your problem\n    precision, recall, _ = precision_recall_curve(y_test[:, i], y_pred_proba[:, i])\n    average_precisions.append(average_precision_score(y_test[:, i], y_pred_proba[:, i]))\n    roc_aucs.append(roc_auc_score(y_test[:, i], y_pred_proba[:, i]))\n\n    # Plot precision-recall curves for each class\n    plt.plot(recall, precision, lw=2, label=f'Class {i + 1} (AP = {average_precisions[i]:.2f}, AUC = {roc_aucs[i]:.2f})')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class')\nplt.show()\n\n# Create a DataFrame for the legend information\nlegend_data = {'Class': [f'Class {i + 1}' for i in range(n_classes)],\n               'Average Precision': average_precisions,\n               'AUC': roc_aucs}\nlegend_df = pd.DataFrame(legend_data)\nlegend_df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:24.364361Z","iopub.execute_input":"2023-12-14T07:06:24.364758Z","iopub.status.idle":"2023-12-14T07:06:25.775847Z","shell.execute_reply.started":"2023-12-14T07:06:24.364723Z","shell.execute_reply":"2023-12-14T07:06:25.774854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test_indices and y_test_pred are obtained as mentioned in your code\n# Convert to binary format\ny_test_binary = label_binarize(y_test_indices, classes=range(n_classes))\ny_pred_binary = label_binarize(y_test_pred, classes=range(n_classes))\n\n# Calculate precision, recall, and AP\nmodel2_precision = precision_score(y_test_binary, y_pred_binary, average='weighted')\nmodel2_recall = recall_score(y_test_binary, y_pred_binary, average='weighted')\nmodel2_AP = average_precision_score(y_test_binary, y_pred_binary, average='weighted')\n\nprint(f'Weighted-Averaged Precision: {model2_precision:.2f}')\nprint(f'Weighted-Averaged Recall: {model2_recall:.2f}')\nprint(f'Weighted-Averaged AP: {model2_AP:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:25.777369Z","iopub.execute_input":"2023-12-14T07:06:25.777766Z","iopub.status.idle":"2023-12-14T07:06:25.896693Z","shell.execute_reply.started":"2023-12-14T07:06:25.777727Z","shell.execute_reply":"2023-12-14T07:06:25.895655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_3\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Model - 3 ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"final_features_3 = np.concatenate([vgg16_features,\n                                 resnet50_features,\n                                 mobilenet_v2_features,\n                                 densenet_features], axis=-1)\nprint('Final feature maps shape', final_features_3.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:25.912398Z","iopub.execute_input":"2023-12-14T07:06:25.912775Z","iopub.status.idle":"2023-12-14T07:06:25.991985Z","shell.execute_reply.started":"2023-12-14T07:06:25.912745Z","shell.execute_reply":"2023-12-14T07:06:25.990835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_3_train\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 3.1 Train - Test Split ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"original_value_counts = pd.Series(y.argmax(axis=1)).value_counts(normalize=True)\n\nX_train, X_test, y_train, y_test = train_test_split(final_features_3, y, test_size=0.1, stratify=y, random_state=42)\n\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\ntrain_value_counts = pd.Series(y_train_indices).value_counts(normalize=True)\ntest_value_counts = pd.Series(y_test_indices).value_counts(normalize=True)\n\nfig, ax = plt.subplots(figsize=(20, 20))\n\nbar_width = 0.2\nindex = np.arange(len(original_value_counts))\n\nbar1 = ax.barh(index, original_value_counts, bar_width, label='Main Data')\nbar2 = ax.barh(index, train_value_counts, bar_width, label='Train Set', left=original_value_counts)\nbar4 = ax.barh(index, test_value_counts, bar_width, label='Test Set', left=original_value_counts + train_value_counts)\n\nax.set_xlabel('Percentages')\nax.set_title('Class Distribution')\nax.set_yticks(index)\nax.set_yticklabels(original_value_counts.index)\nax.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:25.993201Z","iopub.execute_input":"2023-12-14T07:06:25.993560Z","iopub.status.idle":"2023-12-14T07:06:30.391873Z","shell.execute_reply.started":"2023-12-14T07:06:25.993532Z","shell.execute_reply":"2023-12-14T07:06:30.390860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_3_class\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 3.2 Class Weight ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"# from sklearn.utils.class_weight import compute_class_weight\n# from sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(np.argmax(y_train, axis=1))\n\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n\nclass_weights_dict = {class_num: weight for class_num, weight in zip(np.unique(y_train_encoded), class_weights)}\n\nprint(\"Class Weights Dictionary:\")\nprint(class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:30.393312Z","iopub.execute_input":"2023-12-14T07:06:30.393894Z","iopub.status.idle":"2023-12-14T07:06:30.407035Z","shell.execute_reply.started":"2023-12-14T07:06:30.393864Z","shell.execute_reply":"2023-12-14T07:06:30.406016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_1_fit\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 3.3 Training Model ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"#Prepare call backs\nEarlyStop_callback = EarlyStopping(monitor='val_loss', verbose=1,mode = 'min', patience=15, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:30.408475Z","iopub.execute_input":"2023-12-14T07:06:30.409595Z","iopub.status.idle":"2023-12-14T07:06:30.414781Z","shell.execute_reply.started":"2023-12-14T07:06:30.409554Z","shell.execute_reply":"2023-12-14T07:06:30.413863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare DNN model\nmodel_3 = keras.models.Sequential([\n    InputLayer(X_train.shape[1:]),\n    Dropout(0.5),\n    Dense(n_classes, activation='softmax')\n])\n\nmodel_3.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['Recall'])\n\n#Train simple DNN on extracted features.\nhistory_3 = model_3.fit(X_train, y_train,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_data=(X_test, y_test),\n            callbacks=my_callback,\n            class_weight = class_weights_dict)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:06:30.416357Z","iopub.execute_input":"2023-12-14T07:06:30.416722Z","iopub.status.idle":"2023-12-14T07:06:42.582335Z","shell.execute_reply.started":"2023-12-14T07:06:30.416693Z","shell.execute_reply":"2023-12-14T07:06:42.581291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_3_evaluation\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 3.4 Model Evaluation ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"loss, recall = model_3.evaluate(X_test, y_test, verbose=0)\nprint(\"loss: \", loss)\nprint(\"recall: \", recall)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:42.583753Z","iopub.execute_input":"2023-12-14T07:06:42.584052Z","iopub.status.idle":"2023-12-14T07:06:52.024107Z","shell.execute_reply.started":"2023-12-14T07:06:42.584027Z","shell.execute_reply":"2023-12-14T07:06:52.023155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_3","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:52.025372Z","iopub.execute_input":"2023-12-14T07:06:52.025741Z","iopub.status.idle":"2023-12-14T07:06:52.033766Z","shell.execute_reply.started":"2023-12-14T07:06:52.025711Z","shell.execute_reply":"2023-12-14T07:06:52.032862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_data = history_3.history\n\nloss_df_3 = pd.DataFrame(history_data)\nloss_df_3","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:52.035012Z","iopub.execute_input":"2023-12-14T07:06:52.035311Z","iopub.status.idle":"2023-12-14T07:06:52.051710Z","shell.execute_reply.started":"2023-12-14T07:06:52.035284Z","shell.execute_reply":"2023-12-14T07:06:52.050647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df_3.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:52.053122Z","iopub.execute_input":"2023-12-14T07:06:52.053549Z","iopub.status.idle":"2023-12-14T07:06:52.448999Z","shell.execute_reply.started":"2023-12-14T07:06:52.053513Z","shell.execute_reply":"2023-12-14T07:06:52.448058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix, classification_report\n\n# Assuming y_train and y_test are one-hot encoded, convert them to indices\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\n# Get predicted labels for both training and test datasets\ntrain_pred_prob = model_3.predict(X_train)\ntest_pred_prob = model_3.predict(X_test)\n\ny_train_pred = np.argmax(train_pred_prob, axis=1)\ny_test_pred = np.argmax(test_pred_prob, axis=1)\n\n# Calculate confusion matrix and classification report for training dataset\nprint(\"Training Dataset:\")\nprint(confusion_matrix(y_train_indices, y_train_pred))\nprint(classification_report(y_train_indices, y_train_pred))\n\n# Calculate confusion matrix and classification report for test dataset\nprint(\"\\nTest Dataset:\")\nprint(confusion_matrix(y_test_indices, y_test_pred))\nprint(classification_report(y_test_indices, y_test_pred))\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:06:52.450521Z","iopub.execute_input":"2023-12-14T07:06:52.450917Z","iopub.status.idle":"2023-12-14T07:06:53.774186Z","shell.execute_reply.started":"2023-12-14T07:06:52.450881Z","shell.execute_reply":"2023-12-14T07:06:53.773124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test is in multilabel-indicator format\ny_pred_proba = model_3.predict(X_test)\n\n# Calculate average precision and area under the ROC curve for each class\naverage_precisions = []\nroc_aucs = []\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(n_classes):  # n_classes is the number of classes in your problem\n    precision, recall, _ = precision_recall_curve(y_test[:, i], y_pred_proba[:, i])\n    average_precisions.append(average_precision_score(y_test[:, i], y_pred_proba[:, i]))\n    roc_aucs.append(roc_auc_score(y_test[:, i], y_pred_proba[:, i]))\n\n    # Plot precision-recall curves for each class\n    plt.plot(recall, precision, lw=2, label=f'Class {i + 1} (AP = {average_precisions[i]:.2f}, AUC = {roc_aucs[i]:.2f})')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class')\nplt.show()\n\n# Create a DataFrame for the legend information\nlegend_data = {'Class': [f'Class {i + 1}' for i in range(n_classes)],\n               'Average Precision': average_precisions,\n               'AUC': roc_aucs}\nlegend_df = pd.DataFrame(legend_data)\nlegend_df","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:53.775337Z","iopub.execute_input":"2023-12-14T07:06:53.775655Z","iopub.status.idle":"2023-12-14T07:06:55.227049Z","shell.execute_reply.started":"2023-12-14T07:06:53.775626Z","shell.execute_reply":"2023-12-14T07:06:55.226105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import precision_score, recall_score, average_precision_score\n# from sklearn.preprocessing import label_binarize\n\n# Assuming y_test_indices and y_test_pred are obtained as mentioned in your code\n# Convert to binary format\ny_test_binary = label_binarize(y_test_indices, classes=range(n_classes))\ny_pred_binary = label_binarize(y_test_pred, classes=range(n_classes))\n\n# Calculate precision, recall, and AP\nmodel3_precision = precision_score(y_test_binary, y_pred_binary, average='weighted')\nmodel3_recall = recall_score(y_test_binary, y_pred_binary, average='weighted')\nmodel3_AP = average_precision_score(y_test_binary, y_pred_binary, average='weighted')\n\nprint(f'Weighted-Averaged Precision: {model3_precision:.2f}')\nprint(f'Weighted-Averaged Recall: {model3_recall:.2f}')\nprint(f'Weighted-Averaged AP: {model3_AP:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:55.228285Z","iopub.execute_input":"2023-12-14T07:06:55.228607Z","iopub.status.idle":"2023-12-14T07:06:55.349886Z","shell.execute_reply.started":"2023-12-14T07:06:55.228581Z","shell.execute_reply":"2023-12-14T07:06:55.348695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_4\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Model - 4 ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"final_features_4 = np.concatenate([inception_features,\n                                 resnet50_features,\n                                 nasnet_features,\n                                 densenet_features], axis=-1)\nprint('Final feature maps shape', final_features_4.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:55.351355Z","iopub.execute_input":"2023-12-14T07:06:55.351710Z","iopub.status.idle":"2023-12-14T07:06:55.491553Z","shell.execute_reply.started":"2023-12-14T07:06:55.351680Z","shell.execute_reply":"2023-12-14T07:06:55.490377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_4_train\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 4.1 Train - Test Split ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"original_value_counts = pd.Series(y.argmax(axis=1)).value_counts(normalize=True)\n\nX_train, X_test, y_train, y_test = train_test_split(final_features_4, y, test_size=0.1, stratify=y, random_state=42)\n\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\ntrain_value_counts = pd.Series(y_train_indices).value_counts(normalize=True)\ntest_value_counts = pd.Series(y_test_indices).value_counts(normalize=True)\n\nfig, ax = plt.subplots(figsize=(20, 20))\n\nbar_width = 0.2\nindex = np.arange(len(original_value_counts))\n\nbar1 = ax.barh(index, original_value_counts, bar_width, label='Main Data')\nbar2 = ax.barh(index, train_value_counts, bar_width, label='Train Set', left=original_value_counts)\nbar4 = ax.barh(index, test_value_counts, bar_width, label='Test Set', left=original_value_counts + train_value_counts)\n\nax.set_xlabel('Percentages')\nax.set_title('Class Distribution')\nax.set_yticks(index)\nax.set_yticklabels(original_value_counts.index)\nax.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:55.492887Z","iopub.execute_input":"2023-12-14T07:06:55.493176Z","iopub.status.idle":"2023-12-14T07:06:59.069915Z","shell.execute_reply.started":"2023-12-14T07:06:55.493150Z","shell.execute_reply":"2023-12-14T07:06:59.068533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_4_class\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 4.2 Class Weight ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"# from sklearn.utils.class_weight import compute_class_weight\n# from sklearn.preprocessing import LabelEncoder\n\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(np.argmax(y_train, axis=1))\n\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n\nclass_weights_dict = {class_num: weight for class_num, weight in zip(np.unique(y_train_encoded), class_weights)}\n\nprint(\"Class Weights Dictionary:\")\nprint(class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:59.071360Z","iopub.execute_input":"2023-12-14T07:06:59.071800Z","iopub.status.idle":"2023-12-14T07:06:59.087337Z","shell.execute_reply.started":"2023-12-14T07:06:59.071744Z","shell.execute_reply":"2023-12-14T07:06:59.086311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_4_fit\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 4.3 Training Model ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"#Prepare call backs\nEarlyStop_callback = EarlyStopping(monitor='val_loss', verbose=1,mode = 'min', patience=15, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:06:59.088382Z","iopub.execute_input":"2023-12-14T07:06:59.088721Z","iopub.status.idle":"2023-12-14T07:06:59.094136Z","shell.execute_reply.started":"2023-12-14T07:06:59.088695Z","shell.execute_reply":"2023-12-14T07:06:59.093245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare DNN model\nmodel_4 = keras.models.Sequential([\n    InputLayer(X_train.shape[1:]),\n    Dropout(0.5),\n    Dense(n_classes, activation='softmax')\n])\n\nmodel_4.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['Recall'])\n\n#Train simple DNN on extracted features.\nhistory_4 = model_4.fit(X_train, y_train,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_data=(X_test, y_test),\n            callbacks=my_callback,\n            class_weight = class_weights_dict)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:06:59.095586Z","iopub.execute_input":"2023-12-14T07:06:59.095963Z","iopub.status.idle":"2023-12-14T07:07:11.625971Z","shell.execute_reply.started":"2023-12-14T07:06:59.095926Z","shell.execute_reply":"2023-12-14T07:07:11.624947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_4_evaluation\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 4.4 Model Evaluation ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"loss, recall = model_4.evaluate(X_test, y_test, verbose=0)\nprint(\"loss: \", loss)\nprint(\"recall: \", recall)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:11.627131Z","iopub.execute_input":"2023-12-14T07:07:11.627448Z","iopub.status.idle":"2023-12-14T07:07:11.868377Z","shell.execute_reply.started":"2023-12-14T07:07:11.627409Z","shell.execute_reply":"2023-12-14T07:07:11.867281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_4","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:11.869651Z","iopub.execute_input":"2023-12-14T07:07:11.869949Z","iopub.status.idle":"2023-12-14T07:07:11.876089Z","shell.execute_reply.started":"2023-12-14T07:07:11.869923Z","shell.execute_reply":"2023-12-14T07:07:11.875207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_data = history_4.history\n\nloss_df_4 = pd.DataFrame(history_data)\nloss_df_4","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:11.877247Z","iopub.execute_input":"2023-12-14T07:07:11.877565Z","iopub.status.idle":"2023-12-14T07:07:11.895911Z","shell.execute_reply.started":"2023-12-14T07:07:11.877540Z","shell.execute_reply":"2023-12-14T07:07:11.894890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df_4.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:11.897059Z","iopub.execute_input":"2023-12-14T07:07:11.897379Z","iopub.status.idle":"2023-12-14T07:07:12.340502Z","shell.execute_reply.started":"2023-12-14T07:07:11.897355Z","shell.execute_reply":"2023-12-14T07:07:12.339513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix, classification_report\n\n# Assuming y_train and y_test are one-hot encoded, convert them to indices\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\n# Get predicted labels for both training and test datasets\ntrain_pred_prob = model_4.predict(X_train)\ntest_pred_prob = model_4.predict(X_test)\n\ny_train_pred = np.argmax(train_pred_prob, axis=1)\ny_test_pred = np.argmax(test_pred_prob, axis=1)\n\n# Calculate confusion matrix and classification report for training dataset\nprint(\"Training Dataset:\")\nprint(confusion_matrix(y_train_indices, y_train_pred))\nprint(classification_report(y_train_indices, y_train_pred))\n\n# Calculate confusion matrix and classification report for test dataset\nprint(\"\\nTest Dataset:\")\nprint(confusion_matrix(y_test_indices, y_test_pred))\nprint(classification_report(y_test_indices, y_test_pred))\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:07:12.341980Z","iopub.execute_input":"2023-12-14T07:07:12.342387Z","iopub.status.idle":"2023-12-14T07:07:14.112722Z","shell.execute_reply.started":"2023-12-14T07:07:12.342351Z","shell.execute_reply":"2023-12-14T07:07:14.111663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test is in multilabel-indicator format\ny_pred_proba = model_4.predict(X_test)\n\n# Calculate average precision and area under the ROC curve for each class\naverage_precisions = []\nroc_aucs = []\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(n_classes):  # n_classes is the number of classes in your problem\n    precision, recall, _ = precision_recall_curve(y_test[:, i], y_pred_proba[:, i])\n    average_precisions.append(average_precision_score(y_test[:, i], y_pred_proba[:, i]))\n    roc_aucs.append(roc_auc_score(y_test[:, i], y_pred_proba[:, i]))\n\n    # Plot precision-recall curves for each class\n    plt.plot(recall, precision, lw=2, label=f'Class {i + 1} (AP = {average_precisions[i]:.2f}, AUC = {roc_aucs[i]:.2f})')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class')\nplt.show()\n\n# Create a DataFrame for the legend information\nlegend_data = {'Class': [f'Class {i + 1}' for i in range(n_classes)],\n               'Average Precision': average_precisions,\n               'AUC': roc_aucs}\nlegend_df = pd.DataFrame(legend_data)\nlegend_df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:14.114500Z","iopub.execute_input":"2023-12-14T07:07:14.114929Z","iopub.status.idle":"2023-12-14T07:07:15.640561Z","shell.execute_reply.started":"2023-12-14T07:07:14.114892Z","shell.execute_reply":"2023-12-14T07:07:15.639518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import precision_score, recall_score, average_precision_score\n# from sklearn.preprocessing import label_binarize\n\n# Assuming y_test_indices and y_test_pred are obtained as mentioned in your code\n# Convert to binary format\ny_test_binary = label_binarize(y_test_indices, classes=range(n_classes))\ny_pred_binary = label_binarize(y_test_pred, classes=range(n_classes))\n\n# Calculate precision, recall, and AP\nmodel4_precision = precision_score(y_test_binary, y_pred_binary, average='weighted')\nmodel4_recall = recall_score(y_test_binary, y_pred_binary, average='weighted')\nmodel4_AP = average_precision_score(y_test_binary, y_pred_binary, average='weighted')\n\nprint(f'Weighted-Averaged Precision: {model4_precision:.2f}')\nprint(f'Weighted-Averaged Recall: {model4_recall:.2f}')\nprint(f'Weighted-Averaged AP: {model4_AP:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:15.642023Z","iopub.execute_input":"2023-12-14T07:07:15.642390Z","iopub.status.idle":"2023-12-14T07:07:15.761934Z","shell.execute_reply.started":"2023-12-14T07:07:15.642357Z","shell.execute_reply":"2023-12-14T07:07:15.760916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_5\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Model - 5 ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"final_features_5 = np.concatenate([mobilenet_v2_features,\n                                 resnet50_features,\n                                 vgg16_features,\n                                 densenet_features], axis=-1)\nprint('Final feature maps shape', final_features_5.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:15.763232Z","iopub.execute_input":"2023-12-14T07:07:15.764562Z","iopub.status.idle":"2023-12-14T07:07:15.841501Z","shell.execute_reply.started":"2023-12-14T07:07:15.764511Z","shell.execute_reply":"2023-12-14T07:07:15.840479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_5_train\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 5.1 Train - Test Split ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"original_value_counts = pd.Series(y.argmax(axis=1)).value_counts(normalize=True)\n\nX_train, X_test, y_train, y_test = train_test_split(final_features_5, y, test_size=0.1, stratify=y, random_state=42)\n\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\ntrain_value_counts = pd.Series(y_train_indices).value_counts(normalize=True)\ntest_value_counts = pd.Series(y_test_indices).value_counts(normalize=True)\n\nfig, ax = plt.subplots(figsize=(20, 20))\n\nbar_width = 0.2\nindex = np.arange(len(original_value_counts))\n\nbar1 = ax.barh(index, original_value_counts, bar_width, label='Main Data')\nbar2 = ax.barh(index, train_value_counts, bar_width, label='Train Set', left=original_value_counts)\nbar4 = ax.barh(index, test_value_counts, bar_width, label='Test Set', left=original_value_counts + train_value_counts)\n\nax.set_xlabel('Percentages')\nax.set_title('Class Distribution')\nax.set_yticks(index)\nax.set_yticklabels(original_value_counts.index)\nax.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:15.842999Z","iopub.execute_input":"2023-12-14T07:07:15.843454Z","iopub.status.idle":"2023-12-14T07:07:19.354547Z","shell.execute_reply.started":"2023-12-14T07:07:15.843396Z","shell.execute_reply":"2023-12-14T07:07:19.353584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_5_class\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 5.2 Class Weight ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(np.argmax(y_train, axis=1))\n\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n\nclass_weights_dict = {class_num: weight for class_num, weight in zip(np.unique(y_train_encoded), class_weights)}\n\nprint(\"Class Weights Dictionary:\")\nprint(class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:19.355736Z","iopub.execute_input":"2023-12-14T07:07:19.356081Z","iopub.status.idle":"2023-12-14T07:07:19.369283Z","shell.execute_reply.started":"2023-12-14T07:07:19.356052Z","shell.execute_reply":"2023-12-14T07:07:19.368301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_5_fit\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 5.3 Training Model ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"#Prepare call backs\nEarlyStop_callback = EarlyStopping(monitor='val_loss', verbose=1,mode = 'min', patience=15, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:07:19.370729Z","iopub.execute_input":"2023-12-14T07:07:19.371127Z","iopub.status.idle":"2023-12-14T07:07:19.377687Z","shell.execute_reply.started":"2023-12-14T07:07:19.371087Z","shell.execute_reply":"2023-12-14T07:07:19.376501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare DNN model\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\n\nmodel_5 = keras.models.Sequential([\n    InputLayer(X_train.shape[1:]),\n    Dropout(0.5),\n    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(n_classes, activation='softmax')\n])\n\noptimizer = Adam(learning_rate=0.00005)\nmodel_5.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['Recall'])\n\n#Train simple DNN on extracted features.\nhistory_5 = model_5.fit(X_train, y_train,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_data=(X_test, y_test),\n            callbacks=my_callback,\n            class_weight = class_weights_dict)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:07:19.379068Z","iopub.execute_input":"2023-12-14T07:07:19.379424Z","iopub.status.idle":"2023-12-14T07:09:35.578292Z","shell.execute_reply.started":"2023-12-14T07:07:19.379397Z","shell.execute_reply":"2023-12-14T07:09:35.577194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_5_evaluation\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 5.4 Model Evaluation ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"loss, recall = model_5.evaluate(X_test, y_test, verbose=0)\nprint(\"loss: \", loss)\nprint(\"recall: \", recall)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:35.579648Z","iopub.execute_input":"2023-12-14T07:09:35.580004Z","iopub.status.idle":"2023-12-14T07:09:35.760652Z","shell.execute_reply.started":"2023-12-14T07:09:35.579971Z","shell.execute_reply":"2023-12-14T07:09:35.759666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_5","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:35.762002Z","iopub.execute_input":"2023-12-14T07:09:35.762311Z","iopub.status.idle":"2023-12-14T07:09:35.768596Z","shell.execute_reply.started":"2023-12-14T07:09:35.762282Z","shell.execute_reply":"2023-12-14T07:09:35.767726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_data = history_5.history\n\nloss_df_5 = pd.DataFrame(history_data)\nloss_df_5","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:35.769761Z","iopub.execute_input":"2023-12-14T07:09:35.770004Z","iopub.status.idle":"2023-12-14T07:09:35.786294Z","shell.execute_reply.started":"2023-12-14T07:09:35.769982Z","shell.execute_reply":"2023-12-14T07:09:35.785253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df_5.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:35.787570Z","iopub.execute_input":"2023-12-14T07:09:35.787892Z","iopub.status.idle":"2023-12-14T07:09:36.118500Z","shell.execute_reply.started":"2023-12-14T07:09:35.787867Z","shell.execute_reply":"2023-12-14T07:09:36.117513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix, classification_report\n\n# Assuming y_train and y_test are one-hot encoded, convert them to indices\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\n# Get predicted labels for both training and test datasets\ntrain_pred_prob = model_5.predict(X_train)\ntest_pred_prob = model_5.predict(X_test)\n\ny_train_pred = np.argmax(train_pred_prob, axis=1)\ny_test_pred = np.argmax(test_pred_prob, axis=1)\n\n# Calculate confusion matrix and classification report for training dataset\nprint(\"Training Dataset:\")\nprint(confusion_matrix(y_train_indices, y_train_pred))\nprint(classification_report(y_train_indices, y_train_pred))\n\n# Calculate confusion matrix and classification report for test dataset\nprint(\"\\nTest Dataset:\")\nprint(confusion_matrix(y_test_indices, y_test_pred))\nprint(classification_report(y_test_indices, y_test_pred))\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:09:36.119925Z","iopub.execute_input":"2023-12-14T07:09:36.120277Z","iopub.status.idle":"2023-12-14T07:09:37.495512Z","shell.execute_reply.started":"2023-12-14T07:09:36.120230Z","shell.execute_reply":"2023-12-14T07:09:37.494414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test is in multilabel-indicator format\ny_pred_proba = model_5.predict(X_test)\n\n# Calculate average precision and area under the ROC curve for each class\naverage_precisions = []\nroc_aucs = []\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(n_classes):  # n_classes is the number of classes in your problem\n    precision, recall, _ = precision_recall_curve(y_test[:, i], y_pred_proba[:, i])\n    average_precisions.append(average_precision_score(y_test[:, i], y_pred_proba[:, i]))\n    roc_aucs.append(roc_auc_score(y_test[:, i], y_pred_proba[:, i]))\n\n    # Plot precision-recall curves for each class\n    plt.plot(recall, precision, lw=2, label=f'Class {i + 1} (AP = {average_precisions[i]:.2f}, AUC = {roc_aucs[i]:.2f})')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class')\nplt.show()\n\n# Create a DataFrame for the legend information\nlegend_data = {'Class': [f'Class {i + 1}' for i in range(n_classes)],\n               'Average Precision': average_precisions,\n               'AUC': roc_aucs}\nlegend_df = pd.DataFrame(legend_data)\nlegend_df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:37.496772Z","iopub.execute_input":"2023-12-14T07:09:37.497117Z","iopub.status.idle":"2023-12-14T07:09:38.907292Z","shell.execute_reply.started":"2023-12-14T07:09:37.497084Z","shell.execute_reply":"2023-12-14T07:09:38.906101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, average_precision_score\nfrom sklearn.preprocessing import label_binarize\n\n# Assuming y_test_indices and y_test_pred are obtained as mentioned in your code\n# Convert to binary format\ny_test_binary = label_binarize(y_test_indices, classes=range(n_classes))\ny_pred_binary = label_binarize(y_test_pred, classes=range(n_classes))\n\n# Calculate precision, recall, and AP\nmodel5_precision = precision_score(y_test_binary, y_pred_binary, average='weighted')\nmodel5_recall = recall_score(y_test_binary, y_pred_binary, average='weighted')\nmodel5_AP = average_precision_score(y_test_binary, y_pred_binary, average='weighted')\n\nprint(f'Weighted-Averaged Precision: {model5_precision:.2f}')\nprint(f'Weighted-Averaged Recall: {model5_recall:.2f}')\nprint(f'Weighted-Averaged AP: {model5_AP:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:38.908741Z","iopub.execute_input":"2023-12-14T07:09:38.909087Z","iopub.status.idle":"2023-12-14T07:09:39.027081Z","shell.execute_reply.started":"2023-12-14T07:09:38.909057Z","shell.execute_reply":"2023-12-14T07:09:39.025935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_6\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Model - 6 ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"final_features_6 = np.concatenate([inception_features,\n                                 xception_features,\n                                 nasnet_features,\n                                    ],axis=-1)\nprint('Final feature maps shape', final_features_6.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:39.028255Z","iopub.execute_input":"2023-12-14T07:09:39.028559Z","iopub.status.idle":"2023-12-14T07:09:39.151444Z","shell.execute_reply.started":"2023-12-14T07:09:39.028530Z","shell.execute_reply":"2023-12-14T07:09:39.150509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_6_train\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 6.1 Train - Test Split ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"original_value_counts = pd.Series(y.argmax(axis=1)).value_counts(normalize=True)\n\nX_train, X_test, y_train, y_test = train_test_split(final_features_6, y, test_size=0.2, stratify=y, random_state=42)\n\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\ntrain_value_counts = pd.Series(y_train_indices).value_counts(normalize=True)\ntest_value_counts = pd.Series(y_test_indices).value_counts(normalize=True)\n\nfig, ax = plt.subplots(figsize=(20, 20))\n\nbar_width = 0.2\nindex = np.arange(len(original_value_counts))\n\nbar1 = ax.barh(index, original_value_counts, bar_width, label='Main Data')\nbar2 = ax.barh(index, train_value_counts, bar_width, label='Train Set', left=original_value_counts)\nbar4 = ax.barh(index, test_value_counts, bar_width, label='Test Set', left=original_value_counts + train_value_counts)\n\nax.set_xlabel('Percentages')\nax.set_title('Class Distribution')\nax.set_yticks(index)\nax.set_yticklabels(original_value_counts.index)\nax.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:39.152978Z","iopub.execute_input":"2023-12-14T07:09:39.153818Z","iopub.status.idle":"2023-12-14T07:09:43.288957Z","shell.execute_reply.started":"2023-12-14T07:09:39.153779Z","shell.execute_reply":"2023-12-14T07:09:43.287891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_6_class\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 6.2 Class Weight ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(np.argmax(y_train, axis=1))\n\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n\nclass_weights_dict = {class_num: weight for class_num, weight in zip(np.unique(y_train_encoded), class_weights)}\n\nprint(\"Class Weights Dictionary:\")\nprint(class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:43.290513Z","iopub.execute_input":"2023-12-14T07:09:43.290909Z","iopub.status.idle":"2023-12-14T07:09:43.305918Z","shell.execute_reply.started":"2023-12-14T07:09:43.290873Z","shell.execute_reply":"2023-12-14T07:09:43.304896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_6_fit\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 6.3 Training Model ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"batch_size = 64\nepochs = 1000","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:43.307365Z","iopub.execute_input":"2023-12-14T07:09:43.307700Z","iopub.status.idle":"2023-12-14T07:09:43.312414Z","shell.execute_reply.started":"2023-12-14T07:09:43.307673Z","shell.execute_reply":"2023-12-14T07:09:43.311415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare call backs\nEarlyStop_callback = EarlyStopping(monitor='val_loss', verbose=1,mode = 'min', patience=15, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:09:43.313763Z","iopub.execute_input":"2023-12-14T07:09:43.314161Z","iopub.status.idle":"2023-12-14T07:09:43.323576Z","shell.execute_reply.started":"2023-12-14T07:09:43.314126Z","shell.execute_reply":"2023-12-14T07:09:43.322524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import regularizers\n#Prepare DNN model\nmodel_6 = keras.models.Sequential([\n    InputLayer(X_train.shape[1:]),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(n_classes, activation='softmax', kernel_regularizer=regularizers.l1(0.001)\n         )])\n\nfrom keras.optimizers import Adam\n\ncustom_optimizer = Adam(learning_rate=0.005)\n\nmodel_6.compile(optimizer=custom_optimizer,\n              loss='categorical_crossentropy',\n              metrics=['Recall'])\n\n#model_6.compile(optimizer='adam',\n #             loss='categorical_crossentropy',\n  #            metrics=['Recall'])\n\n#Train simple DNN on extracted features.\nhistory_6 = model_6.fit(X_train, y_train,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_data=(X_test, y_test),\n            callbacks=my_callback,\n            class_weight = class_weights_dict\n                       )","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:09:43.324763Z","iopub.execute_input":"2023-12-14T07:09:43.325052Z","iopub.status.idle":"2023-12-14T07:10:24.162304Z","shell.execute_reply.started":"2023-12-14T07:09:43.325027Z","shell.execute_reply":"2023-12-14T07:10:24.161202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_6_evaluation\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 6.4 Model Evaluation ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"from sklearn.metrics import log_loss\ny_pred_proba = model_6.predict(X_test)\n\ny_true = np.argmax(y_test, axis=1)\n\nloss = log_loss(y_true, y_pred_proba)\n\nprint(f\"Multi Class Log Loss: {loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:24.163811Z","iopub.execute_input":"2023-12-14T07:10:24.164228Z","iopub.status.idle":"2023-12-14T07:10:24.599299Z","shell.execute_reply.started":"2023-12-14T07:10:24.164190Z","shell.execute_reply":"2023-12-14T07:10:24.598269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, recall = model_6.evaluate(X_test, y_test, verbose=0)\nprint(\"loss: \", loss)\nprint(\"recall: \", recall)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:24.600566Z","iopub.execute_input":"2023-12-14T07:10:24.600883Z","iopub.status.idle":"2023-12-14T07:10:24.995964Z","shell.execute_reply.started":"2023-12-14T07:10:24.600855Z","shell.execute_reply":"2023-12-14T07:10:24.994857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_6","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:24.997373Z","iopub.execute_input":"2023-12-14T07:10:24.997765Z","iopub.status.idle":"2023-12-14T07:10:25.004320Z","shell.execute_reply.started":"2023-12-14T07:10:24.997734Z","shell.execute_reply":"2023-12-14T07:10:25.003118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_data = history_6.history\n\nloss_df_6 = pd.DataFrame(history_data)\nloss_df_6","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:25.005768Z","iopub.execute_input":"2023-12-14T07:10:25.006104Z","iopub.status.idle":"2023-12-14T07:10:25.027040Z","shell.execute_reply.started":"2023-12-14T07:10:25.006076Z","shell.execute_reply":"2023-12-14T07:10:25.025885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df_6.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:25.028545Z","iopub.execute_input":"2023-12-14T07:10:25.028865Z","iopub.status.idle":"2023-12-14T07:10:25.369668Z","shell.execute_reply.started":"2023-12-14T07:10:25.028838Z","shell.execute_reply":"2023-12-14T07:10:25.368679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix, classification_report\n\n# Assuming y_train and y_test are one-hot encoded, convert them to indices\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\n# Get predicted labels for both training and test datasets\ntrain_pred_prob = model_6.predict(X_train)\ntest_pred_prob = model_6.predict(X_test)\n\ny_train_pred = np.argmax(train_pred_prob, axis=1)\ny_test_pred = np.argmax(test_pred_prob, axis=1)\n\n# Calculate confusion matrix and classification report for training dataset\nprint(\"Training Dataset:\")\nprint(confusion_matrix(y_train_indices, y_train_pred))\nprint(classification_report(y_train_indices, y_train_pred))\n\n# Calculate confusion matrix and classification report for test dataset\nprint(\"\\nTest Dataset:\")\nprint(confusion_matrix(y_test_indices, y_test_pred))\nprint(classification_report(y_test_indices, y_test_pred))\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:10:25.370850Z","iopub.execute_input":"2023-12-14T07:10:25.371148Z","iopub.status.idle":"2023-12-14T07:10:27.154878Z","shell.execute_reply.started":"2023-12-14T07:10:25.371122Z","shell.execute_reply":"2023-12-14T07:10:27.153667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test is in multilabel-indicator format\ny_pred_proba = model_6.predict(X_test)\n\n# Calculate average precision and area under the ROC curve for each class\naverage_precisions = []\nroc_aucs = []\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(n_classes):  # n_classes is the number of classes in your problem\n    precision, recall, _ = precision_recall_curve(y_test[:, i], y_pred_proba[:, i])\n    average_precisions.append(average_precision_score(y_test[:, i], y_pred_proba[:, i]))\n    roc_aucs.append(roc_auc_score(y_test[:, i], y_pred_proba[:, i]))\n\n    # Plot precision-recall curves for each class\n    plt.plot(recall, precision, lw=2, label=f'Class {i + 1} (AP = {average_precisions[i]:.2f}, AUC = {roc_aucs[i]:.2f})')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class')\nplt.show()\n\n# Create a DataFrame for the legend information\nlegend_data = {'Class': [f'Class {i + 1}' for i in range(n_classes)],\n               'Average Precision': average_precisions,\n               'AUC': roc_aucs}\nlegend_df = pd.DataFrame(legend_data)\nlegend_df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:27.156495Z","iopub.execute_input":"2023-12-14T07:10:27.157195Z","iopub.status.idle":"2023-12-14T07:10:28.868316Z","shell.execute_reply.started":"2023-12-14T07:10:27.157154Z","shell.execute_reply":"2023-12-14T07:10:28.867305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import precision_score, recall_score, average_precision_score\n# from sklearn.preprocessing import label_binarize\n\n# Assuming y_test_indices and y_test_pred are obtained as mentioned in your code\n# Convert to binary format\ny_test_binary = label_binarize(y_test_indices, classes=range(n_classes))\ny_pred_binary = label_binarize(y_test_pred, classes=range(n_classes))\n\n# Calculate precision, recall, and AP\nmodel6_precision = precision_score(y_test_binary, y_pred_binary, average='weighted')\nmodel6_recall = recall_score(y_test_binary, y_pred_binary, average='weighted')\nmodel6_AP = average_precision_score(y_test_binary, y_pred_binary, average='weighted')\n\nprint(f'Weighted-Averaged Precision: {model6_precision:.2f}')\nprint(f'Weighted-Averaged Recall: {model6_recall:.2f}')\nprint(f'Weighted-Averaged AP: {model6_AP:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:28.869837Z","iopub.execute_input":"2023-12-14T07:10:28.870562Z","iopub.status.idle":"2023-12-14T07:10:29.032143Z","shell.execute_reply.started":"2023-12-14T07:10:28.870530Z","shell.execute_reply":"2023-12-14T07:10:29.031092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_7\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Model - 7 ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"final_features_7 = np.concatenate([resnet50_features, \n                                   nasnet_features, \n                                   densenet_features], axis=-1)\nprint('Final feature maps shape', final_features_7.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:29.033590Z","iopub.execute_input":"2023-12-14T07:10:29.033991Z","iopub.status.idle":"2023-12-14T07:10:29.143390Z","shell.execute_reply.started":"2023-12-14T07:10:29.033954Z","shell.execute_reply":"2023-12-14T07:10:29.142168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_7_train\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 7.1 Train - Test Split ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\noriginal_value_counts = pd.Series(y.argmax(axis=1)).value_counts(normalize=True)\n\nX_train, X_test, y_train, y_test = train_test_split(final_features_7, y, test_size=0.2, stratify=y, random_state=42)\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=42)\n\ny_train_indices = np.argmax(y_train, axis=1)\ny_val_indices = np.argmax(y_val, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\ntrain_value_counts = pd.Series(y_train_indices).value_counts(normalize=True)\nval_value_counts = pd.Series(y_val_indices).value_counts(normalize=True)\ntest_value_counts = pd.Series(y_test_indices).value_counts(normalize=True)\n\nfig, ax = plt.subplots(figsize=(20, 20))\n\nbar_width = 0.2\nindex = np.arange(len(original_value_counts))\n\nbar1 = ax.barh(index, original_value_counts, bar_width, label='Main Data')\nbar2 = ax.barh(index, train_value_counts, bar_width, label='Train Set', left=original_value_counts)\nbar3 = ax.barh(index, val_value_counts, bar_width, label='Validation Set', left=original_value_counts + train_value_counts)\nbar4 = ax.barh(index, test_value_counts, bar_width, label='Test Set', left=original_value_counts + train_value_counts + val_value_counts)\n\nax.set_xlabel('Percentage')\nax.set_title('Class Distribution')\nax.set_yticks(index)\nax.set_yticklabels(original_value_counts.index)\nax.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:29.144674Z","iopub.execute_input":"2023-12-14T07:10:29.144986Z","iopub.status.idle":"2023-12-14T07:10:33.902075Z","shell.execute_reply.started":"2023-12-14T07:10:29.144956Z","shell.execute_reply":"2023-12-14T07:10:33.900750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_7_class\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 7.2 Class Weight ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(np.argmax(y_train, axis=1))\n\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n\nclass_weights_dict = {class_num: weight for class_num, weight in zip(np.unique(y_train_encoded), class_weights)}\n\nprint(\"Class Weights Dictionary:\")\nprint(class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:33.903420Z","iopub.execute_input":"2023-12-14T07:10:33.903748Z","iopub.status.idle":"2023-12-14T07:10:33.916339Z","shell.execute_reply.started":"2023-12-14T07:10:33.903719Z","shell.execute_reply":"2023-12-14T07:10:33.915338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_7_fit\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 7.3 Training Model ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"batch_size = 64\nepochs = 100","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:33.917491Z","iopub.execute_input":"2023-12-14T07:10:33.917791Z","iopub.status.idle":"2023-12-14T07:10:33.923300Z","shell.execute_reply.started":"2023-12-14T07:10:33.917766Z","shell.execute_reply":"2023-12-14T07:10:33.922399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare call backs\nEarlyStop_callback = EarlyStopping(monitor='val_loss', verbose=1, patience=15, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:10:33.924964Z","iopub.execute_input":"2023-12-14T07:10:33.925371Z","iopub.status.idle":"2023-12-14T07:10:33.934542Z","shell.execute_reply.started":"2023-12-14T07:10:33.925334Z","shell.execute_reply":"2023-12-14T07:10:33.933628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_7 = keras.models.Sequential([\n    InputLayer(X_train.shape[1:]),\n    Dropout(0.8),\n    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(n_classes, activation='softmax')\n])\n\noptimizer = Adam(learning_rate=0.00005)\nmodel_7.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['Recall'])\n\n#Train simple DNN on extracted features.\nhistory_7= model_7.fit(X_train, y_train,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_data=(X_val, y_val),\n            callbacks=my_callback,\n            class_weight = class_weights_dict)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:10:33.935694Z","iopub.execute_input":"2023-12-14T07:10:33.935998Z","iopub.status.idle":"2023-12-14T07:11:37.835317Z","shell.execute_reply.started":"2023-12-14T07:10:33.935973Z","shell.execute_reply":"2023-12-14T07:11:37.834299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_7_evaluation\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® 7.4 Model Evaluation ‚ú®</p>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{}},{"cell_type":"code","source":"loss, recall = model_7.evaluate(X_test, y_test, verbose=0)\nprint(\"loss: \", loss)\nprint(\"recall: \", recall)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:11:37.837052Z","iopub.execute_input":"2023-12-14T07:11:37.837858Z","iopub.status.idle":"2023-12-14T07:11:38.355507Z","shell.execute_reply.started":"2023-12-14T07:11:37.837817Z","shell.execute_reply":"2023-12-14T07:11:38.354614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_7","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:11:38.356644Z","iopub.execute_input":"2023-12-14T07:11:38.356953Z","iopub.status.idle":"2023-12-14T07:11:38.363790Z","shell.execute_reply.started":"2023-12-14T07:11:38.356926Z","shell.execute_reply":"2023-12-14T07:11:38.362670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_data = history_7.history\n\nloss_df_7 = pd.DataFrame(history_data)\nloss_df_7","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:11:38.365469Z","iopub.execute_input":"2023-12-14T07:11:38.365913Z","iopub.status.idle":"2023-12-14T07:11:38.384429Z","shell.execute_reply.started":"2023-12-14T07:11:38.365876Z","shell.execute_reply":"2023-12-14T07:11:38.383520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df_7.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:11:38.385763Z","iopub.execute_input":"2023-12-14T07:11:38.386331Z","iopub.status.idle":"2023-12-14T07:11:38.776752Z","shell.execute_reply.started":"2023-12-14T07:11:38.386298Z","shell.execute_reply":"2023-12-14T07:11:38.775700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_train and y_test are one-hot encoded, convert them to indices\ny_train_indices = np.argmax(y_train, axis=1)\ny_test_indices = np.argmax(y_test, axis=1)\n\n# Get predicted labels for both training and test datasets\ntrain_pred_prob = model_7.predict(X_train)\ntest_pred_prob = model_7.predict(X_test)\n\ny_train_pred = np.argmax(train_pred_prob, axis=1)\ny_test_pred = np.argmax(test_pred_prob, axis=1)\n\n# Calculate confusion matrix and classification report for training dataset\nprint(\"Training Dataset:\")\nprint(confusion_matrix(y_train_indices, y_train_pred))\nprint(classification_report(y_train_indices, y_train_pred))\n\n# Calculate confusion matrix and classification report for test dataset\nprint(\"\\nTest Dataset:\")\nprint(confusion_matrix(y_test_indices, y_test_pred))\nprint(classification_report(y_test_indices, y_test_pred))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-14T07:11:38.778637Z","iopub.execute_input":"2023-12-14T07:11:38.779024Z","iopub.status.idle":"2023-12-14T07:11:40.355866Z","shell.execute_reply.started":"2023-12-14T07:11:38.778986Z","shell.execute_reply":"2023-12-14T07:11:40.354875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test is in multilabel-indicator format\ny_pred_proba = model_7.predict(X_test)\n\n# Calculate average precision and area under the ROC curve for each class\naverage_precisions = []\nroc_aucs = []\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(n_classes):  # n_classes is the number of classes in your problem\n    precision, recall, _ = precision_recall_curve(y_test[:, i], y_pred_proba[:, i])\n    average_precisions.append(average_precision_score(y_test[:, i], y_pred_proba[:, i]))\n    roc_aucs.append(roc_auc_score(y_test[:, i], y_pred_proba[:, i]))\n\n    # Plot precision-recall curves for each class\n    plt.plot(recall, precision, lw=2, label=f'Class {i + 1} (AP = {average_precisions[i]:.2f}, AUC = {roc_aucs[i]:.2f})')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Each Class')\nplt.show()\n\n# Create a DataFrame for the legend information\nlegend_data = {'Class': [f'Class {i + 1}' for i in range(n_classes)],\n               'Average Precision': average_precisions,\n               'AUC': roc_aucs}\nlegend_df = pd.DataFrame(legend_data)\nlegend_df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:11:40.357319Z","iopub.execute_input":"2023-12-14T07:11:40.358188Z","iopub.status.idle":"2023-12-14T07:11:42.007632Z","shell.execute_reply.started":"2023-12-14T07:11:40.358158Z","shell.execute_reply":"2023-12-14T07:11:42.006520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming y_test_indices and y_test_pred are obtained as mentioned in your code\n# Convert to binary format\ny_test_binary = label_binarize(y_test_indices, classes=range(n_classes))\ny_pred_binary = label_binarize(y_test_pred, classes=range(n_classes))\n\n# Calculate precision, recall, and AP\nmodel7_precision = precision_score(y_test_binary, y_pred_binary, average='weighted')\nmodel7_recall = recall_score(y_test_binary, y_pred_binary, average='weighted')\nmodel7_AP = average_precision_score(y_test_binary, y_pred_binary, average='weighted')\n\nprint(f'Weighted-Averaged Precision: {model7_precision:.2f}')\nprint(f'Weighted-Averaged Recall: {model7_recall:.2f}')\nprint(f'Weighted-Averaged AP: {model7_AP:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:11:42.009477Z","iopub.execute_input":"2023-12-14T07:11:42.009896Z","iopub.status.idle":"2023-12-14T07:11:42.174732Z","shell.execute_reply.started":"2023-12-14T07:11:42.009860Z","shell.execute_reply":"2023-12-14T07:11:42.173603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_model_comparison\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Model Comparison ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"model_names = [\"Model\"] + [f\"Model {i}\" for i in range(1, 8)]  # Change the range to include Model 6\n\ncompare = pd.DataFrame({\n    \"Model\": model_names,\n    \"Precision\": [model_precision, model1_precision, model2_precision, model3_precision, model4_precision, model5_precision, model6_precision, model7_precision], \n    \"Recall\": [model_recall, model1_recall, model2_recall, model3_recall, model4_recall, model5_recall, model6_recall, model7_recall],  \n    \"AP\": [model_AP, model1_AP, model2_AP, model3_AP, model4_AP, model5_AP, model6_AP, model7_AP] \n})","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:11:42.175944Z","iopub.execute_input":"2023-12-14T07:11:42.176275Z","iopub.status.idle":"2023-12-14T07:11:42.183652Z","shell.execute_reply.started":"2023-12-14T07:11:42.176247Z","shell.execute_reply":"2023-12-14T07:11:42.182530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_palette = \"Reds\" \n\nplt.figure(figsize=(14, 10))\n\nplt.subplot(311)\ncompare_precision = compare.sort_values(by=\"Precision\", ascending=False)\nax = sns.barplot(x=\"Precision\", y=\"Model\", data=compare_precision, palette=new_palette)\nax.bar_label(ax.containers[0], fmt=\"%.3f\", fontsize=10)\nplt.title(\"Precision Comparison\")\n\nplt.subplot(312)\ncompare_recall = compare.sort_values(by=\"Recall\", ascending=False)\nax = sns.barplot(x=\"Recall\", y=\"Model\", data=compare_recall, palette=new_palette)\nax.bar_label(ax.containers[0], fmt=\"%.3f\", fontsize=10)\nplt.title(\"Recall Comparison\")\n\nplt.subplot(313)\ncompare_ap = compare.sort_values(by=\"AP\", ascending=False)\nax = sns.barplot(x=\"AP\", y=\"Model\", data=compare_ap, palette=new_palette)\nax.bar_label(ax.containers[0], fmt=\"%.3f\", fontsize=10)\nplt.title(\"Average Precision Comparison\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:11:42.184989Z","iopub.execute_input":"2023-12-14T07:11:42.185322Z","iopub.status.idle":"2023-12-14T07:11:43.388385Z","shell.execute_reply.started":"2023-12-14T07:11:42.185289Z","shell.execute_reply":"2023-12-14T07:11:43.387345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(3, 3, figsize=(15, 8))\n\nloss_df_1.plot(ax=axs[0, 0])\naxs[0, 0].set_title('Model 0')\naxs[0, 0].set_xlabel('Epochs')\naxs[0, 0].set_ylabel('Loss')\n\nloss_df_1.plot(ax=axs[0, 1])\naxs[0, 1].set_title('Model 1')\naxs[0, 1].set_xlabel('Epochs')\naxs[0, 1].set_ylabel('Loss')\n\nloss_df_2.plot(ax=axs[0, 2])\naxs[0, 2].set_title('Model 2')\naxs[0, 2].set_xlabel('Epochs')\naxs[0, 2].set_ylabel('Loss')\n\nloss_df_3.plot(ax=axs[1, 0])\naxs[1, 0].set_title('Model 3')\naxs[1, 0].set_xlabel('Epochs')\naxs[1, 0].set_ylabel('Loss')\n\nloss_df_4.plot(ax=axs[1, 1])\naxs[1, 1].set_title('Model 4')\naxs[1, 1].set_xlabel('Epochs')\naxs[1, 1].set_ylabel('Loss')\n\nloss_df_5.plot(ax=axs[1, 2])\naxs[1, 2].set_title('Model 5')\naxs[1, 2].set_xlabel('Epochs')\naxs[1, 2].set_ylabel('Loss')\n\nloss_df_6.plot(ax=axs[2, 0])\naxs[2, 0].set_title('Model 6')\naxs[2, 0].set_xlabel('Epochs')\naxs[2, 0].set_ylabel('Loss')\n\nloss_df_7.plot(ax=axs[2, 1])\naxs[2, 1].set_title('Model 7')\naxs[2, 1].set_xlabel('Epochs')\naxs[2, 1].set_ylabel('Loss')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:11:43.389871Z","iopub.execute_input":"2023-12-14T07:11:43.390216Z","iopub.status.idle":"2023-12-14T07:11:46.731110Z","shell.execute_reply.started":"2023-12-14T07:11:43.390185Z","shell.execute_reply":"2023-12-14T07:11:46.730122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"| Model | Architecture | Concatenated Features | Shape of Final Features |\n|-------|--------------|-----------------------|-------------------------|\n| 0     | CNN          | Not applicable       | Not applicable          |\n| 1     | Custom       | Inception, Xception, NASNet, InceptionResNetV2 | Shape: (10222, 9664) |\n| 2     | Custom       | VGG16, ResNet50, MobileNetV2, InceptionResNetV2 | Shape: (10222, 5376) |\n| 3     | Custom       | VGG16, ResNet50, MobileNetV2, DenseNet121 | Shape: (10222, 4864) |\n| 4     | Custom       | Inception, ResNet50, NASNet, DenseNet121 | Shape: (10222, 9152) |\n| 5     | Custom       | MobileNetV2, ResNet50, VGG16, DenseNet121 | Shape: (10222, 4864) |\n| 6     | Custom       | Inception, Xception, NASNet | Shape: (10222, 8128) |\n| 7     | Custom       | ResNet50, NASNet, DenseNet121 | Shape: (10222, 7104) |","metadata":{}},{"cell_type":"code","source":"del X_train, X_test, y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:12:43.736051Z","iopub.execute_input":"2023-12-14T07:12:43.737197Z","iopub.status.idle":"2023-12-14T07:12:43.742007Z","shell.execute_reply.started":"2023-12-14T07:12:43.737148Z","shell.execute_reply":"2023-12-14T07:12:43.740813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"part_2_prediction\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Prediction ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"code","source":"def images_to_array2(data_dir, labels_dataframe, img_size = (224,224,3)):\n    '''\n    Do same as images_to_array but omit some unnecessary steps for test data.\n    '''\n    images_names = labels_dataframe['id']\n    data_size = len(images_names)\n    X = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    for i in tqdm(range(data_size)):\n        image_name = images_names[i]\n        img_dir = os.path.join(data_dir, image_name+'.jpg')\n        img_pixels = tf.keras.preprocessing.image.load_img(img_dir, target_size=img_size)\n        X[i] = img_pixels\n        \n    print('Ouptut Data Size: ', X.shape)\n    return X\n\ntest_data = images_to_array2(test_dir, sample_df, img_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:22:40.932835Z","iopub.execute_input":"2023-12-14T07:22:40.933514Z","iopub.status.idle":"2023-12-14T07:23:12.136700Z","shell.execute_reply.started":"2023-12-14T07:22:40.933412Z","shell.execute_reply":"2023-12-14T07:23:12.134696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_features = get_features(ResNet50, resnet50_preprocessor, img_size, test_data)\ndensenet_features = get_features(DenseNet121, densenet_preprocessor, img_size, test_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:14:26.506008Z","iopub.execute_input":"2023-12-14T07:14:26.506385Z","iopub.status.idle":"2023-12-14T07:15:45.297478Z","shell.execute_reply.started":"2023-12-14T07:14:26.506357Z","shell.execute_reply":"2023-12-14T07:15:45.296489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_v2_features = get_features(MobileNetV2,mobilenet_v2_preprocessor,img_size, test_data)\ninc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, test_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:16:35.170208Z","iopub.execute_input":"2023-12-14T07:16:35.170647Z","iopub.status.idle":"2023-12-14T07:18:05.999531Z","shell.execute_reply.started":"2023-12-14T07:16:35.170612Z","shell.execute_reply":"2023-12-14T07:18:05.998416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_features = get_features(VGG16,vgg16_preprocessor,img_size, test_data)\ninception_features = get_features(InceptionV3, inception_preprocessor, img_size, test_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:20:37.882311Z","iopub.execute_input":"2023-12-14T07:20:37.883021Z","iopub.status.idle":"2023-12-14T07:22:03.024272Z","shell.execute_reply.started":"2023-12-14T07:20:37.882961Z","shell.execute_reply":"2023-12-14T07:22:03.021857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xception_features = get_features(Xception, xception_preprocessor, img_size, test_data)\nnasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, test_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:23:29.255992Z","iopub.execute_input":"2023-12-14T07:23:29.257487Z","iopub.status.idle":"2023-12-14T07:27:44.486696Z","shell.execute_reply.started":"2023-12-14T07:23:29.257396Z","shell.execute_reply":"2023-12-14T07:27:44.484737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Free up some space.\ndel test_data","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:27:50.965137Z","iopub.execute_input":"2023-12-14T07:27:50.965846Z","iopub.status.idle":"2023-12-14T07:27:51.177399Z","shell.execute_reply.started":"2023-12-14T07:27:50.965775Z","shell.execute_reply":"2023-12-14T07:27:51.174975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features = np.concatenate([\n#                                 inception_features,\n                                resnet50_features,   \n#                                  xception_features,\n                                 nasnet_features,\n                                densenet_features,  \n#                                 vgg16_features,\n#                                 mobilenet_v2_features,\n#                                  inc_resnet_features\n                                ],axis=-1)\nprint('Final feature maps shape', test_features.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:33:17.148360Z","iopub.execute_input":"2023-12-14T07:33:17.149491Z","iopub.status.idle":"2023-12-14T07:33:17.276721Z","shell.execute_reply.started":"2023-12-14T07:33:17.149361Z","shell.execute_reply":"2023-12-14T07:33:17.274773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict test labels given test data features.\ny_pred = model_7.predict(test_features, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:33:19.482402Z","iopub.execute_input":"2023-12-14T07:33:19.483111Z","iopub.status.idle":"2023-12-14T07:33:20.928353Z","shell.execute_reply.started":"2023-12-14T07:33:19.483045Z","shell.execute_reply":"2023-12-14T07:33:20.926098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create submission file\nfor b in dog_breeds:\n    sample_df[b] = y_pred[:,class_to_num[b]]\n    \nsample_df.to_csv('submission_model7.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T07:33:24.596189Z","iopub.execute_input":"2023-12-14T07:33:24.597402Z","iopub.status.idle":"2023-12-14T07:33:31.813280Z","shell.execute_reply.started":"2023-12-14T07:33:24.597335Z","shell.execute_reply":"2023-12-14T07:33:31.811567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"summary\"></a>\n# <p style=\"background-color:#3498DB; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Summary ‚ú®</p>","metadata":{"id":"lq-UbgmWUHkh"}},{"cell_type":"markdown","source":"<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{"id":"0Z0Z0zmZVJfS"}},{"cell_type":"markdown","source":"In this study, eight models were applied: one based on CNN and seven utilizing pre-trained architectures. The models were employed as follows:\n\n| Model | Architecture | Concatenated Features | Shape of Final Features |\n|-------|--------------|-----------------------|-------------------------|\n| 0     | CNN          | Not applicable       | Not applicable          |\n| 1     | Custom       | Inception, Xception, NASNet, InceptionResNetV2 | Shape: (10222, 9664) |\n| 2     | Custom       | VGG16, ResNet50, MobileNetV2, InceptionResNetV2 | Shape: (10222, 5376) |\n| 3     | Custom       | VGG16, ResNet50, MobileNetV2, DenseNet121 | Shape: (10222, 4864) |\n| 4     | Custom       | Inception, ResNet50, NASNet, DenseNet121 | Shape: (10222, 9152) |\n| 5     | Custom       | MobileNetV2, ResNet50, VGG16, DenseNet121 | Shape: (10222, 4864) |\n| 6     | Custom       | Inception, Xception, NASNet | Shape: (10222, 8128) |\n| 7     | Custom       | ResNet50, NASNet, DenseNet121 | Shape: (10222, 7104) |\n\nRegularization techniques were employed to address overfitting in these models. Eventually, predictions were made using the model that exhibited the most promising scores.\n\nThe regularization techniques applied included adjustments specific to class weighting, learning rates, dropout rates, and early stopping criteria. Notably, models leveraging class-weight adjustments showed enhanced performance in managing an imbalanced dataset, particularly in terms of recall scores.\n\nAmong the tested models, only the 1st model utilizing class weights was chosen as the final model due to its superior performance.\n\nThis rigorous experimentation and fine-tuning process in deep learning methodologies effectively tackled a Multiclass Classification problem, emphasizing the pivotal role of parameter tuning for optimal model performance.\n\nFurthermore, it's noteworthy that the deep learning models demonstrated resilience against outliers, despite the exclusion of outliers from the analysis.\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"source\"></a>\n<div style=\"background-color:#3498DB; padding:10px; border-radius: 10px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);\">\n    <p style=\"font-weight: bold; color: white;\">Sources Utilized in This Study:</p>\n    <ul>\n        <li><a href=\"https://www.baeldung.com/cs/ml-data-augmentation\" style=\"color: white;\">Baeldung - Machine Learning Data Augmentation</a></li>\n        <li><a href=\"https://towardsdatascience.com/feature-extraction-techniques-d619b56e31be\" style=\"color: white;\">Towards Data Science - Feature Extraction Techniques</a></li>\n        <li><a href=\"https://medium.com/@AnasBrital98/inception-v3-cnn-architecture-explained-691cfb7bba08\" style=\"color: white;\">Medium - Inception V3 CNN Architecture Explained</a></li>\n        <li><a href=\"https://stephan-osterburg.gitbook.io/coding/coding/ml-dl/tensorfow/ch3-xception/xception-architectural-design\" style=\"color: white;\">GitBook - Xception Architectural Design</a></li>\n        <li><a href=\"https://www.mdpi.com/2075-4418/10/12/1064\" style=\"color: white;\">MDPI - DenseNet in Medical Image Analysis</a></li>\n        <li><a href=\"https://www.researchgate.net/figure/A-modified-version-of-Inception-ResNet-V2-Szegedy-et-al-2016-was-used-as-the_fig3_327425789\" style=\"color: white;\">ResearchGate - Inception ResNet V2</a></li>\n        <li><a href=\"https://www.geeksforgeeks.org/vgg-16-cnn-model/\" style=\"color: white;\">GeeksforGeeks - VGG-16 CNN Model</a></li>\n        <li><a href=\"https://towardsdatascience.com/the-annotated-resnet-50-a6c536034758\" style=\"color: white;\">Towards Data Science - The Annotated ResNet-50</a></li>\n        <li><a href=\"https://www.researchgate.net/figure/The-proposed-MobileNetV2-network-architecture_fig1_350152088\" style=\"color: white;\">ResearchGate - MobileNetV2 Network Architecture</a></li>\n        <li><a href=\"https://www.researchgate.net/figure/A-schematic-illustration-of-the-DenseNet-121-architecture-82_fig5_334170752\" style=\"color: white;\">ResearchGate - DenseNet-121 Architecture</a></li>\n    </ul>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<h3 style=\"text-align:center;font-size:200%;\">Progress Bars</h3>\n<div class=\"progress\">\n  <div class=\"progress-bar bg-danger\" role=\"progressbar\" style=\"width: 100%;\" aria-valuenow=\"100\" aria-valuemin=\"100\" aria-valuemax=\"100\">100%</div>\n</div>\n\n","metadata":{"id":"eF9tS6Y7RvDK"}},{"cell_type":"markdown","source":"<a id=\"the_end\"></a>\n# <p style=\"background-color:#FF6961; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® THE END ‚ú®</p>\n\n","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#part_1\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 1</a>\n<a href=\"#part_2\" class=\"btn btn-danger btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Part - 2</a>\n<a href=\"#toc\" class=\"btn btn-warning btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:black;\">Content</a>","metadata":{}},{"cell_type":"markdown","source":"<ul class=\"nav flex-column\" style=\"padding: 0;\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\" style=\"background-color:#FF6961; color:white; text-align: center; margin-bottom: 20px;\"><b>Contributors</b></h3>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n      <span style=\"color:#FF6961; flex-grow: 1;\">Zeynep Parmak</span>\n      <a href=\"https://www.linkedin.com/in/zeynepparmak\" target=\"_blank\">\n        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n      <a href=\"https://www.kaggle.com/zeynepparmak\" target=\"_blank\">\n        <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n    </div>\n  </li>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n      <span style=\"color:#FF6961; flex-grow: 1;\">Ay≈üe U√ßmaklƒ±</span>\n      <a href=\"https://www.linkedin.com/in/ayse-ucmakli\" target=\"_blank\">\n        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n      <a href=\"https://www.kaggle.com/ayeucmakli\" target=\"_blank\">\n        <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n    </div>\n  </li>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n      <span style=\"color:#FF6961; flex-grow: 1;\">Elif Aker</span>\n      <a href=\"https://www.linkedin.com/in/elif-aker\" target=\"_blank\">\n        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n      <a href=\"https://www.kaggle.com/vaktievvel\" target=\"_blank\">\n        <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n    </div>\n  </li>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n        <span style=\"color:#FF6961; flex-grow: 1;\">Safiye Olgun</span>\n        <a href=\"https://www.linkedin.com/in/safiyeolgun/\" target=\"_blank\">\n            <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n        </a>\n        <a href=\"https://www.kaggle.com/safiyeolgun\" target=\"_blank\">\n            <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n        </a>\n    </div>\n</li>\n  <li class=\"nav-item\" style=\"text-align: center; margin-bottom: 20px;\">\n    <div style=\"border: 2px solid #FF6961; padding: 15px; display: flex; flex-direction: row; align-items: center; justify-content: space-between;\">\n      <span style=\"color:#FF6961; flex-grow: 1;\">H√ºseyin Cenik</span>\n      <a href=\"https://www.linkedin.com/in/huseyincenik/\" target=\"_blank\">\n        <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/640px-LinkedIn_logo_initials.png\" alt=\"LinkedIn\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n      <a href=\"https://www.kaggle.com/huseyincenik\" target=\"_blank\">\n        <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle\" width=\"30\" height=\"30\" style=\"margin-left: 10px;\" />\n      </a>\n    </div>\n  </li>\n</ul>\n","metadata":{"id":"M-0g5b4bTppZ"}}]}